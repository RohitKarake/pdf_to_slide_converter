{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMpJWR7crQn22BkI5uzTLKf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"52d16783dbcf4d73a5ae29b08c76f067":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2aef99eedf7c4e69b9a2f123252ad4e9","IPY_MODEL_5318619ad1534b8db34fef92a894234a","IPY_MODEL_84fbaa84183c4b50bb5bb48fb2c74cee"],"layout":"IPY_MODEL_623212de36794b1997b8ca828c588f23"}},"2aef99eedf7c4e69b9a2f123252ad4e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91e49acf6dca4d8099991ee23daa25f5","placeholder":"​","style":"IPY_MODEL_7126a21abc094078afc8e6a875d2b7d1","value":"config.json: 100%"}},"5318619ad1534b8db34fef92a894234a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a239a92c2e845a49c4533badde06cba","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6236e33d3cc449bf96f9e1e341568faa","value":571}},"84fbaa84183c4b50bb5bb48fb2c74cee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18bdbc9580104e7799c64c0f78339a2c","placeholder":"​","style":"IPY_MODEL_a4148470d2724c24a6af647f0ce7eab3","value":" 571/571 [00:00&lt;00:00, 11.8kB/s]"}},"623212de36794b1997b8ca828c588f23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91e49acf6dca4d8099991ee23daa25f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7126a21abc094078afc8e6a875d2b7d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a239a92c2e845a49c4533badde06cba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6236e33d3cc449bf96f9e1e341568faa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"18bdbc9580104e7799c64c0f78339a2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4148470d2724c24a6af647f0ce7eab3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1e64d6f9ba54c258c38760add26c5e4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38622706180d483e998245974dbaa106","IPY_MODEL_7e98376436d641e9b2a679995c26eb56","IPY_MODEL_40089467a7ea4fd68cfc3953e5ca747e"],"layout":"IPY_MODEL_904e107effd94673b45c51a5682cfc62"}},"38622706180d483e998245974dbaa106":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b1394bbafa84b9981463a3476ef81f1","placeholder":"​","style":"IPY_MODEL_0b32f68a185a41e2ad71edc3f358b374","value":"model.safetensors: 100%"}},"7e98376436d641e9b2a679995c26eb56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5372aceb0d24e4988fe7a98e319e169","max":1344951957,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b06f636aa12b43d9ac2f561353986fba","value":1344951957}},"40089467a7ea4fd68cfc3953e5ca747e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6fac8e069fe4b5da8e768b2ef3ae3e1","placeholder":"​","style":"IPY_MODEL_f2c21239889f4455b60914a9934615b6","value":" 1.34G/1.34G [00:15&lt;00:00, 150MB/s]"}},"904e107effd94673b45c51a5682cfc62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b1394bbafa84b9981463a3476ef81f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b32f68a185a41e2ad71edc3f358b374":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5372aceb0d24e4988fe7a98e319e169":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b06f636aa12b43d9ac2f561353986fba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6fac8e069fe4b5da8e768b2ef3ae3e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2c21239889f4455b60914a9934615b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afa71a87371c43c09d2e4a7efff8a817":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a30587fd73a645ad9a2255fbf9d05b6b","IPY_MODEL_b16caa3bfd67458e89bcf064bfae9d4a","IPY_MODEL_e7601a0ea38a4005b2e71c77f997eef1"],"layout":"IPY_MODEL_1b924b415132489a841779eabaa3d770"}},"a30587fd73a645ad9a2255fbf9d05b6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b13981a927d34f80ae26eeb1da0f1e25","placeholder":"​","style":"IPY_MODEL_2150f5f450a443e3aefc58ef99dfef49","value":"tokenizer_config.json: 100%"}},"b16caa3bfd67458e89bcf064bfae9d4a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbff0f83885a44e78918de53b16908a0","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa0b21e8dbe540bbb03c0fa4a74a5778","value":28}},"e7601a0ea38a4005b2e71c77f997eef1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4544a5c825da4786b1c989a9c02ba493","placeholder":"​","style":"IPY_MODEL_766841bfa35e4682bed8ab4327af7787","value":" 28.0/28.0 [00:00&lt;00:00, 1.34kB/s]"}},"1b924b415132489a841779eabaa3d770":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b13981a927d34f80ae26eeb1da0f1e25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2150f5f450a443e3aefc58ef99dfef49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbff0f83885a44e78918de53b16908a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa0b21e8dbe540bbb03c0fa4a74a5778":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4544a5c825da4786b1c989a9c02ba493":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"766841bfa35e4682bed8ab4327af7787":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43f7bb230da34c10b8dc87d895485f26":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c0a460887cb4bab9e70acc3b7b1aeda","IPY_MODEL_ba4b2156462847f99dad10c53b9aca00","IPY_MODEL_94f3de9ca90a4800a891cf4f8e7db3ff"],"layout":"IPY_MODEL_b90dc36adbc94e1eb62066e019709313"}},"2c0a460887cb4bab9e70acc3b7b1aeda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b89fe35218344d6be2e1c5318454a91","placeholder":"​","style":"IPY_MODEL_5724edd8a5f048b0a83d5f361462346a","value":"vocab.txt: 100%"}},"ba4b2156462847f99dad10c53b9aca00":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_04ef243326384dab98ed3acec0730b94","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d20789a5f5e44a0abe26349281aac474","value":231508}},"94f3de9ca90a4800a891cf4f8e7db3ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e33328d776a14934b11559f5b73530fd","placeholder":"​","style":"IPY_MODEL_0b1b6990ba83482cb91a80d1e1a11896","value":" 232k/232k [00:00&lt;00:00, 1.42MB/s]"}},"b90dc36adbc94e1eb62066e019709313":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b89fe35218344d6be2e1c5318454a91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5724edd8a5f048b0a83d5f361462346a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04ef243326384dab98ed3acec0730b94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d20789a5f5e44a0abe26349281aac474":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e33328d776a14934b11559f5b73530fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b1b6990ba83482cb91a80d1e1a11896":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54a2a3a74c0d40349e530792ef30b7e6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01be72c336194c0c88df80ec4cefa736","IPY_MODEL_46e6102f1be84003981cba296e200e0f","IPY_MODEL_623e6e52ea214236857d7d187cff5291"],"layout":"IPY_MODEL_306129f5f496483b9735293e8e2be6e6"}},"01be72c336194c0c88df80ec4cefa736":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2dc32a518d44bc481bf6597b256be9d","placeholder":"​","style":"IPY_MODEL_6387bc369d33406eb6cf6d422d334bd7","value":"tokenizer.json: 100%"}},"46e6102f1be84003981cba296e200e0f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2cfe63504854fa5ad43b977ea429618","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_801ca8421c7644bca48ddce735c46102","value":466062}},"623e6e52ea214236857d7d187cff5291":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b868c8df6ad45dfaac583e568973508","placeholder":"​","style":"IPY_MODEL_2e5b422da0b041da9851fe9b79c363fe","value":" 466k/466k [00:00&lt;00:00, 1.88MB/s]"}},"306129f5f496483b9735293e8e2be6e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2dc32a518d44bc481bf6597b256be9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6387bc369d33406eb6cf6d422d334bd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2cfe63504854fa5ad43b977ea429618":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"801ca8421c7644bca48ddce735c46102":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b868c8df6ad45dfaac583e568973508":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e5b422da0b041da9851fe9b79c363fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86efb7bb95a64da787c2184bd8a39aae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4fa9d54c1fdc4a71beb1c59414e7f695","IPY_MODEL_a5c8a1d19e034de186bc7511d8cb9d78","IPY_MODEL_a5f374a7434b441995000dc2a02eacd5"],"layout":"IPY_MODEL_fd1aeb19c46b42f5ba0595095c7ba79a"}},"4fa9d54c1fdc4a71beb1c59414e7f695":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f555fe333e8431f8f7cb3056088232f","placeholder":"​","style":"IPY_MODEL_8a817d0b1e12400ab9ef092cfbb7d4ac","value":"config.json: 100%"}},"a5c8a1d19e034de186bc7511d8cb9d78":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d403eeae92546508e219f0be0a920e3","max":1404,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0cf1906d627458fb92eabdd57e03782","value":1404}},"a5f374a7434b441995000dc2a02eacd5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97de78fe062d4062930b486cdea1877c","placeholder":"​","style":"IPY_MODEL_e0fe08f7df7547e6a065a175273b8e11","value":" 1.40k/1.40k [00:00&lt;00:00, 47.1kB/s]"}},"fd1aeb19c46b42f5ba0595095c7ba79a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f555fe333e8431f8f7cb3056088232f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a817d0b1e12400ab9ef092cfbb7d4ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d403eeae92546508e219f0be0a920e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0cf1906d627458fb92eabdd57e03782":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97de78fe062d4062930b486cdea1877c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0fe08f7df7547e6a065a175273b8e11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1c5671acb9c4046a3c056d1ce18e1c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5dae98f3b37c445ba5987882b2c6df17","IPY_MODEL_8ce2b435c55546c9a114313c52001581","IPY_MODEL_a4d88e9e343a46218bb3ab08a517f14e"],"layout":"IPY_MODEL_c2133a9750b24164a6033dd687368fc7"}},"5dae98f3b37c445ba5987882b2c6df17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cba8698b37114f7ebb6adf166c22acd3","placeholder":"​","style":"IPY_MODEL_58a0b5692bf949b2ab4dfdc04b7d2825","value":"model.safetensors: 100%"}},"8ce2b435c55546c9a114313c52001581":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_69fd8739bf3b430fa63a96f698d83df2","max":990345061,"min":0,"orientation":"horizontal","style":"IPY_MODEL_302f95d12f6d446da527933779e40105","value":990345061}},"a4d88e9e343a46218bb3ab08a517f14e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f7a852baa064a56ba8b16f2eaedea07","placeholder":"​","style":"IPY_MODEL_ac7b4576a7bb4d468a6ef189f6a67833","value":" 990M/990M [00:11&lt;00:00, 83.5MB/s]"}},"c2133a9750b24164a6033dd687368fc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cba8698b37114f7ebb6adf166c22acd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58a0b5692bf949b2ab4dfdc04b7d2825":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69fd8739bf3b430fa63a96f698d83df2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"302f95d12f6d446da527933779e40105":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f7a852baa064a56ba8b16f2eaedea07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac7b4576a7bb4d468a6ef189f6a67833":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"905fb04e74ad4dd28e7830471a8a1ba0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9fb30b1e3245463f87d1246ca8fbf916","IPY_MODEL_47d61a2551a04df7bc7e09c2c01cb39c","IPY_MODEL_68b8dd16a83d483587c1344c87155fa7"],"layout":"IPY_MODEL_1244da88235e48dd826f8d7931272e68"}},"9fb30b1e3245463f87d1246ca8fbf916":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd667a12a6324e32956ed835df984c54","placeholder":"​","style":"IPY_MODEL_19ea94d484ba4bb0a8bd746594883f28","value":"generation_config.json: 100%"}},"47d61a2551a04df7bc7e09c2c01cb39c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_850e03530342477aae6bcb0164c5171c","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_056690c0a9474687900173dfdbb23594","value":147}},"68b8dd16a83d483587c1344c87155fa7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b351156f32d49a6be8e488aafc7e0a5","placeholder":"​","style":"IPY_MODEL_a9d93ca109d24b2d9ce482ef9871fb00","value":" 147/147 [00:00&lt;00:00, 6.37kB/s]"}},"1244da88235e48dd826f8d7931272e68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd667a12a6324e32956ed835df984c54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19ea94d484ba4bb0a8bd746594883f28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"850e03530342477aae6bcb0164c5171c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"056690c0a9474687900173dfdbb23594":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b351156f32d49a6be8e488aafc7e0a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9d93ca109d24b2d9ce482ef9871fb00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e8418796cf64539b4456ff2f78f9609":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48a42a3585064f688b17f60f3c7d91e3","IPY_MODEL_df062863cfc444f493468b2c51246524","IPY_MODEL_710effb279994c36a379815d224be005"],"layout":"IPY_MODEL_62658c035c664b068d1ef3ba3b6ae07e"}},"48a42a3585064f688b17f60f3c7d91e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e54ba7914c2470ab69998cb95a8381d","placeholder":"​","style":"IPY_MODEL_3ac38d88b4ba451bb5b1d09b222b271f","value":"tokenizer_config.json: 100%"}},"df062863cfc444f493468b2c51246524":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e938e27dae2e4350b8681c6678f152c1","max":2537,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2dd62006727a497589bff0a688494590","value":2537}},"710effb279994c36a379815d224be005":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c61af47ee98c415a818850dae551fb7b","placeholder":"​","style":"IPY_MODEL_42a9a598f24c43f8a294767304d8bcdb","value":" 2.54k/2.54k [00:00&lt;00:00, 45.1kB/s]"}},"62658c035c664b068d1ef3ba3b6ae07e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e54ba7914c2470ab69998cb95a8381d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ac38d88b4ba451bb5b1d09b222b271f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e938e27dae2e4350b8681c6678f152c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dd62006727a497589bff0a688494590":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c61af47ee98c415a818850dae551fb7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42a9a598f24c43f8a294767304d8bcdb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6c995181b814f2c86f68a2624f37fd1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7817d964322040ba8b56f6543768eb15","IPY_MODEL_9cd33ee73dca4f9487db5343b7a8c315","IPY_MODEL_601e505208fc47dc834af8dff21f57cf"],"layout":"IPY_MODEL_6c162d1c082a4b61b8d3b2298d11a82c"}},"7817d964322040ba8b56f6543768eb15":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29b90f2eb2504f4ca5add525d0fa6b63","placeholder":"​","style":"IPY_MODEL_514688e156334916a816ad910a57a358","value":"spiece.model: 100%"}},"9cd33ee73dca4f9487db5343b7a8c315":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6ea2672c2d242c8818fbe3223a53951","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e9cf38d07db84a02a513db1266826d80","value":791656}},"601e505208fc47dc834af8dff21f57cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aff46372410c4ad5ba1eeedc48be1720","placeholder":"​","style":"IPY_MODEL_97e6b0a6b1fd4228a529aef6ae057d45","value":" 792k/792k [00:00&lt;00:00, 8.36MB/s]"}},"6c162d1c082a4b61b8d3b2298d11a82c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29b90f2eb2504f4ca5add525d0fa6b63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"514688e156334916a816ad910a57a358":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6ea2672c2d242c8818fbe3223a53951":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9cf38d07db84a02a513db1266826d80":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aff46372410c4ad5ba1eeedc48be1720":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97e6b0a6b1fd4228a529aef6ae057d45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0af238d0c0f4f5993fbd545b71d0989":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_642718567e864bf98632fd79bcb2e44b","IPY_MODEL_4aae126dd0f34ea395fb81da61fab073","IPY_MODEL_6771b94530754726911d7a14c36a1021"],"layout":"IPY_MODEL_c5b4e72565384a28a198fef8df7f008e"}},"642718567e864bf98632fd79bcb2e44b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_591eef313e114336ad03f85e48659a2b","placeholder":"​","style":"IPY_MODEL_cd1aa0d7072b4c8fbe9a9bd6a99e6115","value":"tokenizer.json: 100%"}},"4aae126dd0f34ea395fb81da61fab073":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d252e083fad4dcd8c1badee46c836f8","max":2424064,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8ddfa0f88b7445d8a0c2270f5cd4f68","value":2424064}},"6771b94530754726911d7a14c36a1021":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78d14c2c5d05484a86c4ef06c10bf555","placeholder":"​","style":"IPY_MODEL_8170461969b6442e8a32087cafca68e0","value":" 2.42M/2.42M [00:00&lt;00:00, 5.84MB/s]"}},"c5b4e72565384a28a198fef8df7f008e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"591eef313e114336ad03f85e48659a2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd1aa0d7072b4c8fbe9a9bd6a99e6115":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d252e083fad4dcd8c1badee46c836f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8ddfa0f88b7445d8a0c2270f5cd4f68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78d14c2c5d05484a86c4ef06c10bf555":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8170461969b6442e8a32087cafca68e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"199cc26e9d0c4f728dd2199874cbb1c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0fc39407453b42ca8f12335d04d83424","IPY_MODEL_606e91575d424e9793fa5b281671d258","IPY_MODEL_edd487ddb75e4ab395d8bd2828437800"],"layout":"IPY_MODEL_5b9c9126b8224c42af11af83f45c007d"}},"0fc39407453b42ca8f12335d04d83424":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a92fd572315940c6981a5294037f1cae","placeholder":"​","style":"IPY_MODEL_447c1ed8d66147269e1698ef49d93784","value":"special_tokens_map.json: 100%"}},"606e91575d424e9793fa5b281671d258":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f431a6179edc458abb3db1fbe9f90a0c","max":2201,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb6ed1a593c34f3b9162e2813f5a0389","value":2201}},"edd487ddb75e4ab395d8bd2828437800":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95b4764e234342a38a4617c2851ebf60","placeholder":"​","style":"IPY_MODEL_2222cdae830e425796e51297a1265f96","value":" 2.20k/2.20k [00:00&lt;00:00, 87.7kB/s]"}},"5b9c9126b8224c42af11af83f45c007d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a92fd572315940c6981a5294037f1cae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"447c1ed8d66147269e1698ef49d93784":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f431a6179edc458abb3db1fbe9f90a0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb6ed1a593c34f3b9162e2813f5a0389":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"95b4764e234342a38a4617c2851ebf60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2222cdae830e425796e51297a1265f96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1faf2e8baa724b269ac28fa108481c5d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c2783f1a0696425aba4d4ca414d22609","IPY_MODEL_47d1b9e5332f486cbc8b911b7b02d822","IPY_MODEL_3a57f17967cf480cbd68d67c0b0e8ecf"],"layout":"IPY_MODEL_b4374a7c4098435e9ad6d93f6ce88d6f"}},"c2783f1a0696425aba4d4ca414d22609":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97c93715285d44f09dcfbadef58e5cad","placeholder":"​","style":"IPY_MODEL_2df0faf25a1c4c58a664d846b6f7985e","value":"Downloading builder script: 100%"}},"47d1b9e5332f486cbc8b911b7b02d822":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2126adf9263f413ebd331ebd622249a6","max":6270,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6d9f700fd7df48a39ffdc7a22a8ffc59","value":6270}},"3a57f17967cf480cbd68d67c0b0e8ecf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11630bc12b134903a472e06dfd73866d","placeholder":"​","style":"IPY_MODEL_7585d17aa6c9485aa7ee33e038ff7967","value":" 6.27k/6.27k [00:00&lt;00:00, 337kB/s]"}},"b4374a7c4098435e9ad6d93f6ce88d6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97c93715285d44f09dcfbadef58e5cad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2df0faf25a1c4c58a664d846b6f7985e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2126adf9263f413ebd331ebd622249a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d9f700fd7df48a39ffdc7a22a8ffc59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"11630bc12b134903a472e06dfd73866d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7585d17aa6c9485aa7ee33e038ff7967":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Following procedure will be followed for this problem statement:\n","# - Convert pdf into xml file using Grobid\n","# - Extract title, headers and text section wise from xml file\n","# - Text processing\n","# - Extractive Summarization using BERT Summarizer\n","# - Predict title from the summarized text for that section using Flan-T5 base model\n","# - Combine all the text into single object for evaluation\n","# - Extract titles and content from the reference ppt of the paper from kaggle dataset\n","# - Perform Evaluation using Rouge Score\n","# - Create slides from the summarrized data and titles\n","# - Create final function which will take file_path as input and gives ppt as the output\n","# - Check by uploading the file and check reference.pptx file after using above function\n","# - Scope"],"metadata":{"id":"pxSvUSkfcMfx"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iCVfObGtbRH3","executionInfo":{"status":"ok","timestamp":1704567534260,"user_tz":-330,"elapsed":9041,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}},"outputId":"7eebd04c-a924-4746-9b61-28e3d3203e46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pygrobid\n","  Downloading pygrobid-0.1.6.tar.gz (3.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pygrobid) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pygrobid) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pygrobid) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pygrobid) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pygrobid) (2023.11.17)\n","Building wheels for collected packages: pygrobid\n","  Building wheel for pygrobid (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pygrobid: filename=pygrobid-0.1.6-py3-none-any.whl size=3939 sha256=4db78193fa85d3b8a431e584097e137b45bf85de276b76f167bd9e3f013f5a54\n","  Stored in directory: /root/.cache/pip/wheels/8e/25/2d/3916f3225cb2b366b89fcb316ffdd86432863e42f86023ce1a\n","Successfully built pygrobid\n","Installing collected packages: pygrobid\n","Successfully installed pygrobid-0.1.6\n"]}],"source":["# Convert the given file into the xml format using Grobid\n","\n","!pip install pygrobid"]},{"cell_type":"code","source":["from grobid.client import GrobidClient"],"metadata":{"id":"-5jgi3c0cGow","executionInfo":{"status":"ok","timestamp":1704567534260,"user_tz":-330,"elapsed":46,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# host = \"localhost\"\n","# port = \"8070\"\n","# client = GrobidClient(host, port)\n","\n","# rsp = client.serve(\"processFulltextDocument\", \"/content/2021.sdp-1.11.pdf\", consolidate_header=\"1\")"],"metadata":{"id":"dxDWfY0TcNrt","executionInfo":{"status":"ok","timestamp":1704567534261,"user_tz":-330,"elapsed":45,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Above cell was giving http connection error while connecting to the Grobid.\n","# Hence using the local setup of Grobid to convert and upload the xml file to this directory.\n","# Following is the procedure to setup Grobid in local\n","\n","# Run following docker command in the shell to run the docker image in local (for windows launch docker desktop before running this)\n","# docker run --rm --init --ulimit core=0 -p 8070:8070 lfoppiano/grobid:0.8.0\n","\n","# Then visit localhost:8070 on browser and upload the pdf file into TEI section and choose Process FullText Document option\n","# Convert and upload the xml file"],"metadata":{"id":"8GBIR0ycchuX","executionInfo":{"status":"ok","timestamp":1704567534261,"user_tz":-330,"elapsed":45,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Extract sectionwise data required for summarization from the converted file\n","import xml.etree.ElementTree as ET"],"metadata":{"id":"A6bL7Kzdc6M9","executionInfo":{"status":"ok","timestamp":1704567534261,"user_tz":-330,"elapsed":44,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def extract_section_wise_text_from_file(file_path):\n","  # Your XML content\n","\n","  # Parse the XML content\n","  tree = ET.parse(file_path)\n","  root = tree.getroot()\n","\n","  # Dictionary to store extracted information\n","  result_dict = {}\n","\n","  # Iterate through each \"div\" element\n","  for div_element in root.iterfind('.//{http://www.tei-c.org/ns/1.0}div'):\n","      div_data = {}\n","\n","      # Extract headers and paragraphs under the \"div\"\n","      headers = [head.text for head in div_element.iterfind('.//{http://www.tei-c.org/ns/1.0}head')]\n","      paragraphs = [p.text for p in div_element.iterfind('.//{http://www.tei-c.org/ns/1.0}p')]\n","\n","      # Store information in the dictionary\n","      div_data['headers'] = headers\n","      div_data['paragraphs'] = paragraphs\n","\n","      # Add the information to the main dictionary\n","      result_dict[f\"Division_{len(result_dict)+1}\"] = div_data\n","  return result_dict"],"metadata":{"id":"ivRWbfQRegA3","executionInfo":{"status":"ok","timestamp":1704567534262,"user_tz":-330,"elapsed":45,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def extract_title_from_file(file_path):\n","  tree = ET.parse(file_path)\n","  root = tree.getroot()\n","\n","  # Find the titleStmt element using the XML namespace\n","  namespace = {'tei': 'http://www.tei-c.org/ns/1.0'}\n","  title_element = root.find('.//tei:titleStmt/tei:title', namespace)\n","\n","  # Extract the text content of the title element\n","  if title_element is not None:\n","      title_text = title_element.text\n","      print(\"Title Text:\", title_text)\n","      return title_text\n","  else:\n","      print(\"Title Element not found in the XML content.\")\n","      return \"unknown title\""],"metadata":{"id":"XIGSq9Z0EgKf","executionInfo":{"status":"ok","timestamp":1704567534262,"user_tz":-330,"elapsed":44,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["research_paper_file_path = \"/content/Paper_cf.pdf.tei.xml\"\n","result_dict = extract_section_wise_text_from_file(research_paper_file_path)\n","paper_title = extract_title_from_file(research_paper_file_path)\n","\n","# Print the result dict\n","for key, value in result_dict.items():\n","    print(f\"{key}:\")\n","    print(f\"Headers: {value['headers']}\")\n","    print(f\"Paragraphs: {value['paragraphs']}\")\n","    print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3WjMAgQgen40","executionInfo":{"status":"ok","timestamp":1704567534262,"user_tz":-330,"elapsed":44,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}},"outputId":"7a047632-5ebd-4060-c844-a8d61b72720d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Title Text: Approximation Algorithms for Combinatorial Auctions with Complement-Free Bidders\n","Division_1:\n","Headers: []\n","Paragraphs: ['In a combinatorial auction m heterogenous indivisible items are sold to n bidders. This paper considers settings in which the valuation functions of the bidders are known to be complement-free (a.k.a. subadditive). We provide several approximation algorithms for the social-welfare maximization problem in such settings. Firstly, we present a logarithmic upper bound for the case that the access to the valuation functions is via demand queries. For the weaker value queries model we provide a tight O( √ m) approximation. Unlike the other algorithms we present, this algorithm is also incentive compatible. Finally, we present two approximation algorithms for the more restricted class of XOS valuations: A simple deterministic algorithm that provides an approximation ratio of 2 and an optimal e e-1 approximation achieved via randomized rounding. We also present optimal lower bounds for both the demand oracles model and the value oracles model.']\n","\n","\n","Division_2:\n","Headers: []\n","Paragraphs: ['1. Introduction. This paper considers the allocation problem in combinatorial auctions. In a combinatorial auction, we have a set of heterogenous indivisible items that are sold to competing bidders. The bidders value bundles of items, rather than only valuing single items individually. Thus, bidders can express complex combinatorial preferences over items.', \"Formally, a set M of items, |M |=m, is sold to n bidders. To denote the i'th bidder's value for each bundle of items S ⊆ M , we use a function v i , where v i (S) denotes the value of the bundle S for bidder i. The function v i is called the valuation of bidder i. Two common assumptions are that for each bidder i, v i is normalized (v i (∅) = 0), and monotone (for each S ⊆ T ⊆ M, v i (S) ≤ v i (T )). The goal is to partition the items between the bidders in a way that maximizes the social welfare -the sum of bidders' values for the bundles that are allocated to them. That is, we wish to find an allocation (S 1 , ..., S m ), S i ∩ S j = ∅ for i = j, that maximizes i v i (S i ).\", 'Two aspects make this problem hard to solve. Firstly, the \"input\" is of exponential size -a naive representation of a valuation will require 2 m values, one for each bundle -while we would like our algorithms to run in time that is polynomial in m and n (the natural parameters of the problem). Secondly, even for valuations that can be succinctly described, the optimization problem is computationally hard. Much work has addressed the problem of identifying special cases that can be efficiently solved or approximated, as well as understanding the underlying computational limitations -see chapters 10 -13 of Cramton et al. ', 'There are two possible approaches to formalizing the computational model. These approaches differ in how the \"input\" is accessed. The first approach calls for fixing some bidding language in which the input valuations are encoded. This approach requires algorithms to run in time that is polynomial in the input length (under this encoding). This kind of approach makes sense in cases in which a sufficiently natural bidding language exists. The second approach treats the valuations as black boxes and assumes that each valuation is represented by oracles that can only answer a fixed type of queries. Three types of queries are commonly considered:', '(i) Value queries: The query specifies a subset S ⊆ M of items and receives the value v i (S) as the reply. This query is very natural from a computer science point of view, but, in general, is quite weak.', '(ii) Demand queries: The query specifies a vector p = (p 1 , ..., p m ) of \"item prices\", and the reply is the set that would be \"demanded\" by the queried bidder given these item prices, i.e., a subset S that maximizes the expression v i (S) -j∈S p j . This query is natural from an economic point of view as it corresponds to the revealed preferences of the bidders (i.e., what is directly observable from their behavior). Blumrosen and Nisan ', '(iii) General queries: In this model we allow the oracles to answer any kind of query (however, each query can only be addressed to a single valuation). This model captures the communication complexity (between the bidders) of the problem, and due to its strength is mostly interesting for proving lower bounds.', 'Combinatorial auctions with general valuations are well understood from a computational perspective: the optimal allocation can be approximated to within a factor of O( √ m) in polynomial time, but not within a factor of m', 'An important special case of combinatorial auctions is the one in which the valuations are known to be complement-free, i.e., all input valuations are known to be subadditive: v(S ∪ T ) ≤ v(S) + v(T ) for all S, T 1 . Lehmann et al. ', 'The allocation problem becomes gradually harder as we move upwards within this hierarchy; a strongly polynomial time algorithm exists if the input valuations are given in the OXS language; a polynomial time algorithm, based on linear programming, exists for the class GS, as shown by Nisan and Segal ', '1.1 Upper Bounds. The main message relayed in this paper is that for the two higher levels of the hierarchy better upper bounds exist: Theorem 1.1 There exists a polynomial-time algorithm that finds an O( log m log log m ) approximation for valuations in the CF class, using demand queries.', 'This algorithm is based on careful randomized rounding of the linear programming relaxation of the problem; a deterministic algorithm is obtained via derandomization.', 'For the more restricted XOS class we obtain improved approximation ratios. Theorem 1.2 There exists a polynomial-time ( e e-1 )-approximation algorithm for valuations given in the XOS language.', 'We also present a 2-approximation algorithm for this class. Although the approximation guarantee is worse than e e-1 , the 2-approximation algorithm has several advantages: it is combinatorial, fast, simple, and deterministic. Moreover, it serves as the main building block for constructions of truthful mechanisms for combinatorial auctions ', '1.2 Lower Bounds. We prove lower bounds for approximation for both CF and XOS. The class CF does not have a natural bidding language and so the lower bound is for the oracle model. The lower bound for the class XOS is actually two separate lower bounds: an NP-hardness result for the bidding language model, and a communication lower bound for the oracle model. No inapproximability result for any of these classes was previously known.', 'Theorem 1.3 Exponential communication is required for approximating the optimal allocation among CF valuations to within a factor of 2 -, for any constant > 0.', 'Theorem 1.4 (1) It is NP-hard to approximate the optimal allocation among valuations given in the XOS language to within any constant factor better than e/(e -1). (2) Exponential communication is required for approximating the optimal allocation among XOS valuations to within any constant factor better than e/(e -1).', 'The last theorem shows that our algorithm for the class XOS is tight.', '1.3 Handling Selfishness. In many settings in which the combinatorial auction problem arises, it is natural to assume that the bidders are selfish. That is, the bidders are interested only in maximizing their own utility, and might therefore misreport their preferences if it suits their interests. We are therefore interested in truthful algorithms that by introducing payments guarantee that if each bidder is to simply report his true value he will maximize his profit. Surprisingly, to date, very few computationally-feasible truthful mechanisms for this problem are known that do not apply only to very restricted single-parameter domains. We present an approximation algorithm that makes use of value queries only, and ensures truthfulness.', 'Theorem 1.5 There exists a truthful polynomial-time algorithm that finds an O( √ m)-approximation for valuations in the class CF using value queries only.', 'This approximation ratio may seem quite bad when contrasted with the fact that for the class of submodular valuations constant-approximation algorithms that use only value queries exist (e.g., by Lehmann et al. ', '1.4 Subsequent Work. Subsequently to this paper, Feige ', 'We now discuss subsequent work related to submodular valuations. Khot, Lipton, Markakis, and Mehta ', 'Vondrak ', 'Another line of research which stemmed in this paper is obtaining truthful mechanisms for combinatorial auctions with complement-free valuations. Dobzinski ', 'Dobzinski and Nisan ', '1.5 Open Questions. This paper and subsequent work determined the optimal bounds possible for the upper levels of the hierarchy, namely combinatorial auctions with XOS and complement-free valuations.', '• The main open question is closing the gap between the known upper and lower bounds for submodular valuations in the demand oracles model. In particular, no communication lower bound is known.', '• It would also be interesting to achieve these approximation ratios using combinatorial algorithms (most state-of-the-art algorithms are based on randomized rounding of the LP relaxation of the problem).', '• Another major open question which is still open is to determine how well truthful mechanisms can approximate the welfare in all levels of the hierarchy.']\n","\n","\n","Division_3:\n","Headers: ['Definition and Representation of XOS.']\n","Paragraphs: ['This section discusses the definition and representation of XOS valuations. Recall, that as discussed in the introduction the class of XOS valuations strictly contains the class of submodular valuations ', 'A valuation is called additive (a.k.a. linear) if for all S ⊆ M , v(S) = Σ j∈S v({j}). Thus, an additive valuation is defined by the values a 1 , ..., a m it assigns to items 1, ..., m respectively. We describe an additive valuations by the following clause:', 'We can now define XOS valuations:', 'where each of the clauses connected by the ⊕ sign represents an additive valuation.', 'We note that the number of clauses t might be exponentially large. We call a clause of an additive valuation w, for which v(S) = max k {w k (S)}, a maximizing clause for S in v (if there are several such clauses we arbitrarily choose one). An XOS oracle is an oracle that given a bundle S returns a maximizing clause for S (for a specific valuation v).', '2.1 Efficiently Simulating XOS and Demand Queries. We now show that if the input is given in the form of an XOS expression, XOS oracles and demand oracles can be simulated in time that is polynomial in the input size. We also prove that if all valuations are submodular then value queries can simulate XOS queries in polynomial time. Therefore, if all valuations are submodular, the algorithm presented in this section requires demand queries only (recall that a value query can be simulated by a polynomial number of demand queries ', 'Proposition 2.1 Given an XOS valuation as an XOS expression, we can evaluate both XOS queries and demand queries in time polynomial in the input size.', 'Proof. Given an XOS valuation and a vector of prices we wish to simulate a demand oracle. First, let us note that it is easy to simulate a demand oracle for an additive valuation in polynomial time, by simply choosing all profitable items. Since the input is given as an XOS formula and each clause is an additive valuation, it is enough to simulate a demand oracle for each clause and choose the most profitable option. The entire process requires time polynomial in the input size.', 'If the input is not given as an XOS expression, then we do not know how to answer XOS queries given only a demand oracle. However, for the more restricted class of submodular valuations, even the weaker value oracle suffices to answer XOS queries, as the following proposition shows: Proposition 2.2 An XOS clause for a bundle S of a submodular valuation v can be calculated in polynomial time using value queries only.', \"Proof. Given a bundle S we show how to construct the corresponding XOS clause. Fix some arbitrary order of the items in S. Without loss of generality, let S = {1, . . . , |S|}. Let t j be the marginal utility of the j'th item given the previous j -1 items:\", 'All that we have to prove is that v(S) = Σ j∈S t j , and that for every T ⊆ S, v(T ) ≥ Σ j∈T t i . For that we use an alternative definition of submodular valuations (see ', 'The first property holds simply by construction. To see that v(T ) ≥ Σ j∈T t i , fix T , and let t T j be the marginal utility of item j in T , using the same order we used in S (that is, order the items in S, and delete items that are not in T , while keeping the relative order of the rest of the items). Recall that an alternative definition of submodular valuation says that the marginal utility does not decrease when items are deleted, hence v(T ) = Σ j∈T t T i ≥ Σ j∈T t i Finally, to show that this clause can be constructed using value queries only, observe that we only have to calculate the marginal utility of an item, which can be done by two value queries for each item.', '3. Approximating the Welfare with Demand Oracles. Randomized rounding of an LPrelaxation of a problem is a standard technique, and our algorithms use it. However, when one attempts randomized rounding on packing problems such as combinatorial auctions the results are not good; A randomized choice will very likely yield non-feasible solutions, unless the probabilities chosen reduce the expected quality of solution by a large O( √ m) factor.', 'Both algorithms we present in this section start with a randomized rounding procedure for obtaining a \"pre-allocation\". This allocation has a value that is close to the optimum, but unfortunately is not feasible. Feasibility issues are handled differently in the complement free and the XOS cases, and indeed a much better ratio is obtained for the XOS case.', 'Before describing the randomized rounding procedure, let us recall the standard LP relaxation for combinatorial auctions:', '-For each item j: Σ i,S|j∈S x i,S ≤ 1 -for each bidder i: Σ S x i,S ≤ 1 -for each i, S: x i,S ≥ 0 Even though the linear program has exponentially many variables, it may still be solved in polynomial time. This is done by solving the dual linear program using the ellipsoid method. Using the ellipsoid method requires a \"separation\" oracle, and this may be directly implemented using the demand oracles of the bidders. This was first proven by Nisan and Segal ', 'The pre-allocation is obtained via randomized rounding as follows: For each bidder i we independently choose a set S i by performing the following random experiment: each set S is chosen with probability x i,S , and the empty set is chosen with probability 1 -Σ S x i,S .', 'Observe that the randomized rounding solution outputs an integral solution with an expected value of OP T * , the optimal fractional solution. However, the solution is not feasible, as an item might be allocated to more than one bidder. The two algorithms we present greatly differ in how they solve this infeasibility.', 'A word about the oracles needed to implement our algorithms. The algorithm for complement-free valuations we present in this section requires access to a demand oracle (for each specific valuation v). Both algorithms for XOS valuations we present require in addition access to an XOS oracle.', '3.1 Complement-Free Valuations. Indeed, the pre-allocation produces a non-feasible solution. However, these non-feasible solutions are only a logarithmic factor away from feasibility (in the sense that with high probability each item is allocated at most a logarithmic number of times). For general valuations this fact does not help, but as we will show it suffices for CF valuations (see also ', 'The main observation at the heart of our algorithm is that one may partition this logarithmicallynon-feasible solution into a logarithmic-size family of feasible solutions. For the case of complement-free valuations, the quality of one of these solutions can be bounded from below.', 'The original version of the algorithm claimed a ratio of O(log m). Feige ', '(i) Use randomized rounding to find a \"pre-allocation\" S 1 , ..., S n of pairs < i, S i > with the following properties, where k = O( log m log log m ):', '). (ii) For each bidder i, partition S i into a disjoint union S i = S 1 i ∪ ... ∪ S k i such that for each 1 ≤ i 1 < i 2 ≤ n and 1 ≤ r ≤ k, it holds that S r i1 ∩ S r i2 = ∅. This is done as follows: for each i = 1, ..., n and each r = 1, ..., k, we let S r i = {j ∈ S i |j appears in exactly r -1 of the sets S 1 , ..., S i-1 }.', '(iii) Find the r that maximizes i v i (S r i ), and for each i allocate T i = S r i to bidder i. (iv) If there is a bidder i with v i (M ) ≥ Σ i v i (T i ) then allocate i all items (and allocate nothing to the rest of the bidders). We now prove the theorem. Towards this end, let us keep track of the \"quality\" of solution implied by the intermediate steps.', '(i) The randomized rounding procedure returns the optimal fractional solution OP T * = Σ i,S x i,S v i (S), which is an upper bound to the value of the integral optimal allocation, OP T . The detailed calculations needed to prove that this step indeed ends with a solution that satisfies all the required conditions are given later. At this point we will indicate the types of calculations used and what they yield. From the first inequality of the LP and using standard probability bounds one can show that for every item j, the probability that it appears in more than k chosen sets is exponentially small in k. The expected value of i v i (S i ) at this stage is only slightly less than Σ i,S x i,S v i (S) = OP T * . It follows that with very high probability none of the required constraints are violated, and thus we have', 'The main point here is that indeed for every fixed r, the sets {S r i } i are pairwise disjoint and are thus a valid allocation. This follows directly from the construction, as every duplicate instances of every item j are allocated to sets S r i with sequentially increasing r. Note that we always keep r ≤ k since each item appears in at most k sets in {S i }.', '(iii) The crucial use of complement-freeness comes here: since for each fixed i, S i = r S r i , the fact that v i is complement free implies that r v i (S r i ) ≥ v i (S i ). By summing over all i we get that', 'It is now clear that by choosing the r that maximizes i v i (S r i ) we get that i v i (S r i ) ≥ OP T * 3k . Thus, the allocation T 1 = S r 1 , ..., T n = S r n is an O( log(m) log log m ) approximation to the optimal allocation (and even to the optimal fractional allocation).', '3.1.1 Details of Stage (i). For each j ∈ M , let E j denote the random variable that indicates whether j was allocated more than k times. Let B be the random variable that indicates whether v i (S i ) < 1  3 OP T * . We will prove that Pr[∨ j E j ∨ B] < 5 6 . We first prove that Pr[∨ j E j ] < 1 n . Fix an item j. Let Z i,j be the random variable that determines whether j ∈ S i . Obviously, Z i,j receives values in {0, 1}. Because of the randomized rounding method we used, we have that the variables {Z i,j } i are independent. We define Z j = Σ i Z i,j (i.e., Z j is the number of times item j appears in {S i }). By the linearity of expectation and the first condition of the LP formulation we have that E[Z j ] ≤ 1. We now use the following known proposition, (see, e.g., the book by Mitzenmacher and Upfal ', 'and thus we have that Pr[item j appears in more than log m 3 log log m bundles in', 'By applying the union bound we get that the probability that any one of the items appears in more than log m', 'm . We will now prove that Pr[B] < 3 4 . W.l.o.g. max i v i (M ) = 1 (otherwise, we can divide all valuations by max i v i (M )). If OP T * ≤ 3, then giving M to the bidder that maximizes v i (M ), is a feasible allocation which provides a good approximation. Therefore, from now on we assume that OP T * > 3. Let A be the random variable that gets the value of Σ i v i (S i ) after step (i). We will see that A ≥ Σ i v i (S) 3 with high probability.', \"We make use of the following corollary from Chebyshev's inequality: Lemma 3.2 Let X be the sum of independent random variables, each of which lies in [0, 1], and let\", 'We can now upper bound the probability that event B occurs.', 'the last inequality is because OP T * > 3. Therefore, using the union bound:', 'We have shown that with good probability it is possible to create a solution for which all the necessary conditions hold.', '3.2 XOS Valuations. The algorithm presented in this section is based on exploiting the structure of the syntactically defined XOS class. Recall that the class of XOS valuations strictly contains submodular valuations.', 'The algorithm starts by obtaining a pre-allocation as described in the beginning of the section, where each bidder gets at most one bundle. The next step is to \"replace\" the valuation of a bidder with the XOS clause that corresponds to the bundle he got in the pre-allocation. Now we find the optimal solution using the \"new\" valuations. Observe that a simple greedy algorithm finds the optimal allocation if all bidders have additive valuations.', 'We are left with showing that the value of the generated allocation is not too far from the optimal fractional solution. Once again, the syntactic properties of XOS come to our aid: we analyze the algorithm by separately setting a lower bound on the contribution of each single item to the total social welfare.', '(i) Obtain a \"pre-allocation\" S 1 , ..., S n using the randomized rounding procedure.', \"(ii) Let (x 1 : p i 1 ∨ ... ∨ x m : p i m ) be the maximizing clause for S i in v i . (iii) Allocate the j'th item to bidder i for which p i j ≥ p i j , for all i ∈ N .\", 'Note that Step (i) requires access to a demand oracle, and Step (ii) requires access to an XOS oracle. We do not know if an XOS oracle can be simulated using demand queries only, in the case of general XOS valuations. However, if a valuation is submodular, a demand oracle (and in fact, a value oracle) suffices, as was shown before. Thus, if all valuations are submodular only demand oracles are needed to implement the algorithm.', 'Theorem 3.2 If all input valuations are XOS then the algorithm produces an allocation that is a (', 'Proof. Observe that the allocation produced by the algorithm is indeed a feasible one. Thus, all that is left to prove is that it achieves the desired approximation ratio.', 'For every bidder i and bundle S, let (x 1 : p', 'm ) be the maximizing clause for S in v i . It holds that:', ') Let Q j be the random variable that equals max i∈N {p i j }, after the randomized rounding step. Let ALG be the random variable that receives the value of the total social welfare after assigning each item as in the algorithm. Due to the properties of XOS valuations, ALG ≥ Σ j Q j . This is because if (x 1 : p', 'm ) is the maximizing clause of S in v i then, by XOS, for every T ⊆ S Σ j∈T p (i,S) j ≤ v i (T ).', 'We will now show that the expectation of Q j is bounded from below by (1', '). Thus, by the linearity of expectation:', 'Proof. Fix an item j. We will lower bound the expected value of E[Q j ] by considering a different way of assigning j. Let X j i = Σ S|j∈S x i,S and', 'That is, X i is the probability that bidder i gets item j in the \"pre-allocation\", and V j i is the expected value of j to bidder i, conditioned on i receiving j in the \"pre-allocation\".', 'Order the bidders in the decreasing order of their V j i \\'s. Without loss of generality, let us assume this order to be 1, ..., n. We assign j to the highest ranked (first) bidder who got item j in the \"pre-allocation\". Denote by T j the expected value of j in this allocation. Observe that', 'is the expected value of item j when j is always assigned to the bidder with the highest (per-item) value for j in the \"pre allocation\" (as in the algorithm). Therefore, to prove the lemma we will bound E[T j ] from below. It is easy to see that', 'Note that, due to the first condition of the LP, X j 1 + ... + X j n ≤ 1. Therefore, we have for every 1 ≤ k ≤ n that:', '1', \"where the last two inequalities are derived using elementary calculus. Define V j n+1 = 0. Multiplying Equation 1 by (V j k -V j k+1 ) for every 1 ≤ k ≤ n, and summing over all k's shows that:\", 'We now present a 2-approximation algorithm for combinatorial auctions with XOS bidders. While the approximation guarantee is worse than the e e-1 guarantee of the previous algorithm, the current algorithm is combinatorial, fast, and simple.', '(i) Initialize S 1 = ... = S n = ∅, and p 1 , ..., p m = 0.', '(ii) For each bidder i = 1...n : (a) Let S i be the demand of bidder i at prices p 1 , ..., p m . (b) For all i < i take away from S i any items from S i : S i ← S i -S i . (c) Let (x 1 : q i 1 ∨, ..., ∨x m : q i m ) be the maximizing clause for S i in v i . (d) For all j ∈ S i , update p j = q i j .', 'Notice that in Step (ii)a we require access to a demand oracle, and in Step (ii)c we require access to an XOS oracle.']\n","\n","\n","Division_4:\n","Headers: ['Theorem 3.3']\n","Paragraphs: [\"The algorithm provides a 2 approximation to the optimal allocation. Proof. For each T ⊆ M , we denote by p i (T ) the sum of the prices of the items in T at the i'th stage of the algorithm. Let ∆ i = p i (M ) -p i-1 (M ), i.e., the total difference in prices between stages (i -1) and i (with p 0 (M ) = 0). Let A 1 , ..., A n be the allocation generated by the algorithm. Let O 1 , ..., O n be the optimal allocation. We will prove the\", 'To do so, we prove three simple lemmas:']\n","\n","\n","Division_5:\n","Headers: [\"The social welfare of the allocation generated by the algorithm is at least the sum of items' prices at the end of the algorithm (after the n'th stage). That is, p\"]\n","Paragraphs: [\"Proof. Consider a specific bidder i. Let T be the bundle assigned to that bidder by the algorithm in stage i. Obviously A i ⊆ T . Because v i is an XOS valuation, we have that p i (A i ) ≤ v i (A i ). However, since the items in A i were not reassigned after the i'th stage, and so their prices were not altered,\", 'Lemma 3.5 The prices assigned to the items throughout the execution of the algorithm are non-decreasing.', \"Proof. By contradiction. Let S be the set that maximizes the demand of the i'th bidder at the i'th stage of the algorithm. Let (x 1 : q 1 ∨ ... ∨ x m : q m ) be the XOS clause of S in v i . Now, assume there is an item j ∈ S for which q j < p i j . v i is an XOS valuation and so we have that Σ t∈(S-{j}) q t ≤ v i (S -{j}) and Σ r∈S q r = v i (S). Hence:\", 'and this is a contradiction to the definition of S.', \"Lemma 3.6 The social welfare of the optimal allocation is at most twice the sum of items' prices at the end of the algorithm. That is,\", 'Proof. Recall that ∆ i represents the \"demand\" of player i at prices p i-1 . Hence, for each i,', 'We have:', 'since the prices do not decrease throughout the algorithm, the following inequality holds:', 'by summing up on both sides of the equation we get:', 'Putting the lemmas together we have that', \"The following example shows that the algorithm cannot achieve an approximation ratio better than 2: consider a combinatorial auction with two goods, a and b, and two bidders. The first bidder's valuation is\", 'A welfare of 2 can be achieved by allocating a to the first bidder, and b to the second bidder. However, the first bidder might wish to get b at the first stage, and the optimal social welfare achieved is only 1. Hence, the approximation ratio achieved by the algorithm is not better than 2.  Proof. Nisan ']\n","\n","\n","Division_6:\n","Headers: ['Lower Bounds']\n","Paragraphs: ['Let us now reduce this combinatorial auction to make the valuations complement free. Define new complement-free valuations as follows: v i (S) = v i (S) + 1, for S = ∅. These new valuations are indeed complement free, since the value of each non-empty bundle is at least 1, and no bundle has a value larger than 2.', 'Consider an instance with valuations v 1 , . . . , v n . We can see that distinguishing between the following cases requires exponential communication: the optimal social welfare is n + 1, and the optimal social welfare is 2n (since distinguishing between these cases is equivalent to distinguishing between the corresponding cases in the auction presented in ', '4.2 Lower Bounds for XOS Valuations. We prove two lower bounds: one in the bidding language model (an NP-hardness result), and one communication lower bound. Theorem 4.2 It is NP-hard to approximate the optimal allocation among valuations given in the XOS language to within any factor better than e/(e -1), for n, m → ∞.', 'Proof. We will show a polynomial-time reduction from MAX-k-COVER. MAX-k-Cover is defined as follows: Given m items, and a collection of subsets of these items, the objective is to maximize the number of items which can be covered by k subsets. Feige ', \"Observe that every choice of k subsets in the MAX-k-COVER corresponds to an allocation in the combinatorial auction with the same value, by assigning all items in set i to bidder i (and avoid assigning one item to more then one bidder). In the other direction, every allocation corresponds to a choice of k sets in MAX-k-COVER with at least the social welfare value: choose k subsets, so that subset i contains the items in the clause maximizing bidder i's gain. Hence, we are guaranteed that the number of items covered is no less than the social welfare. The theorem follows.\", 'Next we prove an unconditional communication lower bound. The proof is based on reduction from the approximate-disjointness problem using a probabilistic construction. The reduction relies on a combinatorial structure that guarantees the required gap between the optimal solution and all other solutions. We first define this structure, and then prove its existence via the probabilistic method.', 'Theorem 4.3 Every protocol for approximating combinatorial auctions with XOS bidders to a factor of', 'for every > 0, requires exponential communication. This lower bound also applies for randomized settings.', 'Proof. We will prove our lower bound by reducing from the approximate disjointness problem. In this problem, there are n players, each player i holds a string A i which specifies a subset of {1, ..., t}. The goal is to distinguish between the following two extreme cases:', 'Alon et al. ', 'We show a reduction from the approximate-disjointness problem on vectors of size t = e 2m n to the problem of finding an optimal solution in combinatorial auctions with XOS bidders. We then prove a communication lower bound for distinguishing between the case the optimal value is m and the case it is', ']. We will create a set F = {P s } s=1,...,t , where each P s is a partition of M into n disjoint subsets {P 1 s i , ..., P n s i }. This set of partitions will have the following property: can only result in changing the allocation to a suboptimal one, hence decreasing the utility of the bidder. Thus bidding truthfully is the best action for each bidder', 'The obvious drawback of using the VCG mechanism is that it requires us to find the optimal solution. In many settings finding the optimal solution is not computationally feasible, and this is true in particular in the settings considered in this paper. In general, obtaining an approximate solution using an approximation algorithm and using the VCG payment scheme (paying each bidder the sum of the utilities of the rest of the bidders) does not result in a truthful mechanism. In fact, Nisan and Ronen ', 'An algorithm is maximal in range if it limits the range of possible allocations to a smaller set, and finds the optimal allocation within this restricted range. Incentive compatibility immediately follows using the same argumentation as before since we find the optimal allocation in the restricted range. The main challenge in the design of these algorithms is therefore to identify a subset of the range in which complete optimization is computationally feasible, and then showing that the optimal solution within the restricted set of solutions always provides the required approximation ratio.']\n","\n","\n","Division_7:\n","Headers: ['5.2']\n","Paragraphs: ['The Algorithm. We present a maximal in range algorithm for combinatorial auctions with complement-free bidders. This algorithm makes use of value queries only. The approximation ratio of this algorithm is O( √ m). In contrast, Dobzinski and Schapira ', '(i) Query each bidder i for v i (M ), and for v i ({j}), for each item j.', '(ii) Construct a bipartite graph by defining a vertex a j for each item j, and a vertex b i for each bidder i. Let the set of edges be E = ∪ i∈N,j∈M (a j , b i ). Define the cost of each edge (a j , b i ) to be v i ({j}). Compute the maximum weighted matching |P | in the graph.', \"(iii) If the valuation of the bidder i that maximizes v i (M ) is higher than the value of |P |, allocate all items to i. Otherwise, for each edge (a j , b i ) ∈ P allocate the j'th item to the i'th bidder.\"]\n","\n","\n","Division_8:\n","Headers: ['Theorem 5.1 If all the valuations are complement free, the algorithm provides an O( √ m)-approximation']\n","Paragraphs: ['to the optimal allocation in polynomial time, and is incentive compatible.', \"Proof. Observe that the algorithm's running time is polynomial in n and m, since maximal weighted matching in bipartite graphs can be solved in polynomial time (in m and n).\", 'The algorithm is clearly a maximal-in-range algorithm, and thus incentive compatibility is guaranteed by the use of the VCG payment scheme. Let us now prove that the algorithm provides the desired approximation ratio. Let OP T = {T 1 , ..., T k , Q 1 , ..., Q l } be the optimal allocation in the original auction, where for each 1', 'The first case we consider is when Σ', '√ m (otherwise, more than m items were allocated), for the bidder i that maximizes', 'Thus, by assigning all items to bidder i we get the desired approximation ratio.']\n","\n","\n","Division_9:\n","Headers: ['Consider the case in which Σ']\n","Paragraphs: ['|T i | (this is due to the CF property:', 'By assigning c i to bidder i we get an allocation in which every bidder gets at most one item with a social welfare of Σ k i=1 v i ({c i })', 'm . The second allocation, therefore, guarantees at least that social welfare. We conclude that the approximation ratio the algorithm guarantees is at least O( √ m).', '6. A Lower Bound for the Value Oracles Model. The proof of the lower bound takes a concrete complexity approach. That is, the input is given as a black box that can only answer a specific type of queries. We only measure the number of queries an algorithm must make in order to achieve a certain approximation ratio. In particular we ignore any computational work that needs to be done. We stress that the lower bound we achieve does not depend on any unproven computational assumption. Theorem 6.1 Approximating a combinatorial auction with XOS bidders to a factor of O(m 1 2 -), for any constant > 0, requires an exponential number of value queries.', 'Proof. Fix a small constant δ > 0. We shall construct a combinatorial auction with m items and k = √ m bidders. For every S, let a S be the additive valuation that assigns a value of 1 to each item j ∈ S, and 0 to each item j / ∈ S. Let ā be the additive valuation that assigns every item j ∈ M a value of 1+δ {a S (T )}, ā(T ))', 'Thus, each v i is a maximum over additive valuations, and thus is an XOS valuation.', 'Choose, uniformly at random, a partition of the items into √ m disjoint bundles of items T 1 , . . . , T k such that for each i, |T i | = √ m. Define v 1 , . . . , v k as follows:', 'v i (T ) = max{v i (T ), a T i (T )} Again, each v i is a maximum over additive valuations, and thus is an XOS valuation.', \"We now prove that for every player i, it takes an exponential number of value queries to distinguish between the case that i's valuation is v i and the case that i's valuation is v i . Notice that the optimal welfare if the valuations are v 1 . . . , v k is Θ(m 1 2 +2δ ), while the optimal social-welfare if the valuations are v 1 . . . , v k is m. Hence, the fact that it requires an exponential number of value queries to distinguish between the valuation profiles v 1 . . . , v k and v 1 . . . , v k implies that an O(m 1 2 -2δ )-approximation algorithm requires an exponential number of value queries.\", 'Consider a specific player i. Fix a bundle S of at most m 1 2 +δ . It holds that v i (S) = max{|S|, (1 + δ)m 2δ }. v i might assign a value higher than v i to S but only if', 'Observe that T i is selected uniformly at random. Thus, we can use the Chernoff bounds (Claim 4.2), and claim that Pr[|S ∩ T i | > (1 + δ)m 2δ ] is exponentially small. Now, consider a bundle S of size greater than m 1 2 +δ . v i will assign to S the value of (1 + δ) |S| m 1 2 -δ . v i might assign S a higher value, but only if', 'Again, using the fact that T i is chosen uniformly at random we claim that that Pr[|S', \"-δ ] is exponentially small. We conclude that for every bundle S, only with exponentially small probability does one gather sufficient information to distinguish between the case that i's valuation is v i and the case that it is v i . Hence, with constant probability it requires an exponential number of value queries to distinguish between v i and v i . This concludes the proof of the theorem.\"]\n","\n","\n","Division_10:\n","Headers: ['7.']\n","Paragraphs: ['Acknowledgments. We thank Daniel Lehmann for comments on an earlier draft of this paper. This research is supported by a grant from the Israeli Science Foundation. The third author is supported by Supported by NSF grant 0331548.']\n","\n","\n","Division_11:\n","Headers: []\n","Paragraphs: ['Definition 4.1 A set of partitions F = {P s } s=1,...,t is said to have the (n, )-covering property if for every choice of indices 1 ≤ s 1 , s 2 , ...s n ≤ t, such that no two are equal, it holds that', 'Lemma 4.1 For every > 0, there exists a set F of partitions with the (n, )-covering property of size', 'Proof. We use probabilistic construction to obtain such a set: each partition P s will be chosen independently at random (each element will be placed in exactly one of the P i s with equal probability). We will require the following version of the Chernoff bounds: Lemma 4.2 Let X 1 , ..., X m be independent random variables that take values in {0, 1}, such that for all i, Pr[X i = 1] = p for some p. Then, the following holds, for 0 ≤ ≤ 1:', 'Fix indices: 1 ≤ s 1 , s 2 , ..., s n ≤ t, such that no two are equal. For every j ∈ M let Y j be the random variable that receives a value of 1 if j ∈ ∪ n i=1 P i si and 0 otherwise. Observe that', 'Using the last claim, we have that for any 0 < < 1:', 'Since there are at most t n choices of such indices we have that as long as t n < e', 'such a set of partitions exists.', 'We are now left with describing the reduction. Assume an instance of the approximate-disjointness problem on vectors of size t = e', ', in which player i receives the string A i ⊆ {1, ..., t}. We reduce it into a combinatorial auction with n bidders, each with XOS valuation, in the following manner:', \"Let M = {1, ..., m}. Player i will construct the collection B i = {P i s |s ∈ A i }. Bidder i's valuation will consist of |B i | clauses: ⊗ T ∈B i (∨ t∈T t = 1). In words, each clause corresponds to a set the player is interested in, and this clause gives a value of 1 to an item if it belongs to the wanted set, and 0 otherwise.\", 'Observe that if there exists s ∈ ∩A i , then there is an allocation in which all items are allocated, and the value of the bundle each player gets is simply the number of items he gets. Thus, the value of this allocation is m. On the other hand, if for every i = j, A i ∩A j = ∅ then the value of the optimal solution is at most', 'The second observation is since the sets have the (n, )-covering property, so the players get together a value of at most ((1', ')m from the allocated items. Since the communication complexity of the approximate-disjointness problem is Ω( t n 4 ), in our case it is Ω(e', '). In particular, as long as m 1-> n, and for any constant 0 < < 1, the communication complexity is exponential. This concludes the proof of the theorem.', '5. Truthful Approximations using Value Queries.', '5.1 VCG and Maximal in Range Algorithms. Arguably the main positive result of mechanism design is the VCG payment scheme. Let us describe this payment scheme when applied to combinatorial auctions. First, find the optimal solution (O 1 , ..., O n ), and allocate accordingly. Then, pay each bidder the sum of the utilities of the rest of the bidders. That is, bidder i receives a payment of Σ k =i v k (O k ). Let us examine the total utility of bidder i: v i (O i ) + Σ k =i v k (O k ) (the value he gains from the bundle he got plus his payment). Hence, the total utility of each bidder is equal to the value of the allocation. Observe that the allocation that maximizes the utility of the bidders is the optimal one. Bidding untruthfully']\n","\n","\n","Division_12:\n","Headers: []\n","Paragraphs: ['Definition 4.1 A set of partitions F = {P s } s=1,...,t is said to have the (n, )-covering property if for every choice of indices 1 ≤ s 1 , s 2 , ...s n ≤ t, such that no two are equal, it holds that', 'Lemma 4.1 For every > 0, there exists a set F of partitions with the (n, )-covering property of size', 'Proof. We use probabilistic construction to obtain such a set: each partition P s will be chosen independently at random (each element will be placed in exactly one of the P i s with equal probability). We will require the following version of the Chernoff bounds: Lemma 4.2 Let X 1 , ..., X m be independent random variables that take values in {0, 1}, such that for all i, Pr[X i = 1] = p for some p. Then, the following holds, for 0 ≤ ≤ 1:', 'Fix indices: 1 ≤ s 1 , s 2 , ..., s n ≤ t, such that no two are equal. For every j ∈ M let Y j be the random variable that receives a value of 1 if j ∈ ∪ n i=1 P i si and 0 otherwise. Observe that', 'Using the last claim, we have that for any 0 < < 1:', 'Since there are at most t n choices of such indices we have that as long as t n < e', 'such a set of partitions exists.', 'We are now left with describing the reduction. Assume an instance of the approximate-disjointness problem on vectors of size t = e', ', in which player i receives the string A i ⊆ {1, ..., t}. We reduce it into a combinatorial auction with n bidders, each with XOS valuation, in the following manner:', \"Let M = {1, ..., m}. Player i will construct the collection B i = {P i s |s ∈ A i }. Bidder i's valuation will consist of |B i | clauses: ⊗ T ∈B i (∨ t∈T t = 1). In words, each clause corresponds to a set the player is interested in, and this clause gives a value of 1 to an item if it belongs to the wanted set, and 0 otherwise.\", 'Observe that if there exists s ∈ ∩A i , then there is an allocation in which all items are allocated, and the value of the bundle each player gets is simply the number of items he gets. Thus, the value of this allocation is m. On the other hand, if for every i = j, A i ∩A j = ∅ then the value of the optimal solution is at most', 'The second observation is since the sets have the (n, )-covering property, so the players get together a value of at most ((1', ')m from the allocated items. Since the communication complexity of the approximate-disjointness problem is Ω( t n 4 ), in our case it is Ω(e', '). In particular, as long as m 1-> n, and for any constant 0 < < 1, the communication complexity is exponential. This concludes the proof of the theorem.', '5. Truthful Approximations using Value Queries.', '5.1 VCG and Maximal in Range Algorithms. Arguably the main positive result of mechanism design is the VCG payment scheme. Let us describe this payment scheme when applied to combinatorial auctions. First, find the optimal solution (O 1 , ..., O n ), and allocate accordingly. Then, pay each bidder the sum of the utilities of the rest of the bidders. That is, bidder i receives a payment of Σ k =i v k (O k ). Let us examine the total utility of bidder i: v i (O i ) + Σ k =i v k (O k ) (the value he gains from the bundle he got plus his payment). Hence, the total utility of each bidder is equal to the value of the allocation. Observe that the allocation that maximizes the utility of the bidders is the optimal one. Bidding untruthfully']\n","\n","\n","Division_13:\n","Headers: []\n","Paragraphs: []\n","\n","\n"]}]},{"cell_type":"code","source":["# combining the content for each division\n","for key, value in result_dict.items():\n","    value[\"headers\"] = \" \".join(value[\"headers\"])\n","    value[\"paragraphs\"] = \" \".join(value[\"paragraphs\"])"],"metadata":{"id":"5n0d7Qwxe72Z","executionInfo":{"status":"ok","timestamp":1704567534262,"user_tz":-330,"elapsed":36,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def combine_content_for_each_division(input_dict):\n","  for key, value in input_dict.items():\n","    value[\"headers\"] = \" \".join(value[\"headers\"])\n","    value[\"paragraphs\"] = \" \".join(value[\"paragraphs\"])\n","  return input_dict"],"metadata":{"id":"PnCHm8al1Ozu","executionInfo":{"status":"ok","timestamp":1704567534263,"user_tz":-330,"elapsed":36,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Remove duplicate entries\n","\n","# list to track values and their corresponding keys\n","value_counts = []\n","\n","# List to store keys to remove\n","keys_to_remove = []\n","\n","# Iterate through the original dictionary\n","for key, value in result_dict.items():\n","    # If the value is already in the value_counts dictionary, add the key to the keys_to_remove list\n","    if value[\"paragraphs\"] in value_counts or value[\"paragraphs\"] == \"\":\n","        keys_to_remove.append(key)\n","    else:\n","        # Otherwise, add the value to the value_counts dictionary\n","        value_counts.append(value[\"paragraphs\"])\n","\n","# Remove the keys outside the loop\n","print(keys_to_remove)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V1l8-YGefo2s","executionInfo":{"status":"ok","timestamp":1704567534263,"user_tz":-330,"elapsed":36,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}},"outputId":"ffe3e24a-d85c-47a0-990e-068541156b19"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["['Division_12', 'Division_13']\n"]}]},{"cell_type":"code","source":["def remove_duplicate_entries(input_dict):\n","  # list to track values and their corresponding keys\n","  value_counts = []\n","\n","  # List to store keys to remove\n","  keys_to_remove = []\n","\n","  # Iterate through the original dictionary\n","  for key, value in input_dict.items():\n","      # If the value is already in the value_counts dictionary, add the key to the keys_to_remove list\n","      if value[\"paragraphs\"] in value_counts or value[\"paragraphs\"] == \"\":\n","          keys_to_remove.append(key)\n","      else:\n","          # Otherwise, add the value to the value_counts dictionary\n","          value_counts.append(value[\"paragraphs\"])\n","\n","  # Remove the keys outside the loop\n","  print(keys_to_remove)\n","  for key in keys_to_remove:\n","    input_dict.pop(key)\n","\n","  return input_dict"],"metadata":{"id":"CPS1yWyH1nvM","executionInfo":{"status":"ok","timestamp":1704567534263,"user_tz":-330,"elapsed":12,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["for key in keys_to_remove:\n","    result_dict.pop(key)"],"metadata":{"id":"VI0cGlAnfxtT","executionInfo":{"status":"ok","timestamp":1704567534264,"user_tz":-330,"elapsed":12,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Exctractive text summarization using BERT Extractive Summarizer\n","# Reasons to select Extractive Text Summarization technique:\n","# 1. As the pdf documents can be too long and passing the whole document content to the LLM model wont be possible everytime.\n","# 2. Abstractive Summarization technique can give random output based on its creativity which will not be related to the actual context.\n","# 3. We need to create content for slides which will be done section wise hence to get relatable and fast output we will use Extractive Summarization.\n","!pip install bert-extractive-summarizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5NFWQ5Zf1Zw","executionInfo":{"status":"ok","timestamp":1704567548066,"user_tz":-330,"elapsed":13814,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}},"outputId":"a815372b-387e-4a84-d8d3-83b24cf5c262"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bert-extractive-summarizer\n","  Downloading bert_extractive_summarizer-0.10.1-py3-none-any.whl (25 kB)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from bert-extractive-summarizer) (4.35.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from bert-extractive-summarizer) (1.2.2)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from bert-extractive-summarizer) (3.6.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->bert-extractive-summarizer) (3.2.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (8.1.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.0.10)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (0.10.3)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (4.66.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (1.10.13)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (23.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->bert-extractive-summarizer) (3.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (0.20.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (2023.6.3)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->bert-extractive-summarizer) (0.4.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers->bert-extractive-summarizer) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers->bert-extractive-summarizer) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->bert-extractive-summarizer) (2023.11.17)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->bert-extractive-summarizer) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->bert-extractive-summarizer) (0.1.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy->bert-extractive-summarizer) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->bert-extractive-summarizer) (2.1.3)\n","Installing collected packages: bert-extractive-summarizer\n","Successfully installed bert-extractive-summarizer-0.10.1\n"]}]},{"cell_type":"code","source":["from summarizer import Summarizer\n","bert_model = Summarizer()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301,"referenced_widgets":["52d16783dbcf4d73a5ae29b08c76f067","2aef99eedf7c4e69b9a2f123252ad4e9","5318619ad1534b8db34fef92a894234a","84fbaa84183c4b50bb5bb48fb2c74cee","623212de36794b1997b8ca828c588f23","91e49acf6dca4d8099991ee23daa25f5","7126a21abc094078afc8e6a875d2b7d1","6a239a92c2e845a49c4533badde06cba","6236e33d3cc449bf96f9e1e341568faa","18bdbc9580104e7799c64c0f78339a2c","a4148470d2724c24a6af647f0ce7eab3","a1e64d6f9ba54c258c38760add26c5e4","38622706180d483e998245974dbaa106","7e98376436d641e9b2a679995c26eb56","40089467a7ea4fd68cfc3953e5ca747e","904e107effd94673b45c51a5682cfc62","8b1394bbafa84b9981463a3476ef81f1","0b32f68a185a41e2ad71edc3f358b374","d5372aceb0d24e4988fe7a98e319e169","b06f636aa12b43d9ac2f561353986fba","d6fac8e069fe4b5da8e768b2ef3ae3e1","f2c21239889f4455b60914a9934615b6","afa71a87371c43c09d2e4a7efff8a817","a30587fd73a645ad9a2255fbf9d05b6b","b16caa3bfd67458e89bcf064bfae9d4a","e7601a0ea38a4005b2e71c77f997eef1","1b924b415132489a841779eabaa3d770","b13981a927d34f80ae26eeb1da0f1e25","2150f5f450a443e3aefc58ef99dfef49","bbff0f83885a44e78918de53b16908a0","aa0b21e8dbe540bbb03c0fa4a74a5778","4544a5c825da4786b1c989a9c02ba493","766841bfa35e4682bed8ab4327af7787","43f7bb230da34c10b8dc87d895485f26","2c0a460887cb4bab9e70acc3b7b1aeda","ba4b2156462847f99dad10c53b9aca00","94f3de9ca90a4800a891cf4f8e7db3ff","b90dc36adbc94e1eb62066e019709313","0b89fe35218344d6be2e1c5318454a91","5724edd8a5f048b0a83d5f361462346a","04ef243326384dab98ed3acec0730b94","d20789a5f5e44a0abe26349281aac474","e33328d776a14934b11559f5b73530fd","0b1b6990ba83482cb91a80d1e1a11896","54a2a3a74c0d40349e530792ef30b7e6","01be72c336194c0c88df80ec4cefa736","46e6102f1be84003981cba296e200e0f","623e6e52ea214236857d7d187cff5291","306129f5f496483b9735293e8e2be6e6","a2dc32a518d44bc481bf6597b256be9d","6387bc369d33406eb6cf6d422d334bd7","e2cfe63504854fa5ad43b977ea429618","801ca8421c7644bca48ddce735c46102","0b868c8df6ad45dfaac583e568973508","2e5b422da0b041da9851fe9b79c363fe"]},"id":"tymd9sHvf85d","executionInfo":{"status":"ok","timestamp":1704567616691,"user_tz":-330,"elapsed":68645,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}},"outputId":"451affb1-0f7b-4e7e-fcb4-3337544d2037"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52d16783dbcf4d73a5ae29b08c76f067"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1e64d6f9ba54c258c38760add26c5e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afa71a87371c43c09d2e4a7efff8a817"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43f7bb230da34c10b8dc87d895485f26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54a2a3a74c0d40349e530792ef30b7e6"}},"metadata":{}}]},{"cell_type":"code","source":["def generate_extractive_summary(text):\n","  ext_summary = bert_model(text, min_length = 40, max_length = 150)\n","  summary = \"\".join(ext_summary)\n","  return summary"],"metadata":{"id":"TyPCGWQ9hH3x","executionInfo":{"status":"ok","timestamp":1704567616691,"user_tz":-330,"elapsed":8,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["!pip install torch\n","!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFjHMxk1hReq","executionInfo":{"status":"ok","timestamp":1704567638751,"user_tz":-330,"elapsed":22066,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}},"outputId":"15ebf363-860f-4ada-d1b0-c021c936164d"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForSeq2SeqLM\n","from transformers import AutoTokenizer"],"metadata":{"id":"DB4X6dVIhRgs","executionInfo":{"status":"ok","timestamp":1704567638751,"user_tz":-330,"elapsed":26,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# We will then use the T5 base model to extract appropriate title for the slides as every time the headers extracted from the doc\n","# will not be correct.\n","\n","model_name='google/flan-t5-base'\n","\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241,"referenced_widgets":["86efb7bb95a64da787c2184bd8a39aae","4fa9d54c1fdc4a71beb1c59414e7f695","a5c8a1d19e034de186bc7511d8cb9d78","a5f374a7434b441995000dc2a02eacd5","fd1aeb19c46b42f5ba0595095c7ba79a","5f555fe333e8431f8f7cb3056088232f","8a817d0b1e12400ab9ef092cfbb7d4ac","1d403eeae92546508e219f0be0a920e3","b0cf1906d627458fb92eabdd57e03782","97de78fe062d4062930b486cdea1877c","e0fe08f7df7547e6a065a175273b8e11","f1c5671acb9c4046a3c056d1ce18e1c7","5dae98f3b37c445ba5987882b2c6df17","8ce2b435c55546c9a114313c52001581","a4d88e9e343a46218bb3ab08a517f14e","c2133a9750b24164a6033dd687368fc7","cba8698b37114f7ebb6adf166c22acd3","58a0b5692bf949b2ab4dfdc04b7d2825","69fd8739bf3b430fa63a96f698d83df2","302f95d12f6d446da527933779e40105","2f7a852baa064a56ba8b16f2eaedea07","ac7b4576a7bb4d468a6ef189f6a67833","905fb04e74ad4dd28e7830471a8a1ba0","9fb30b1e3245463f87d1246ca8fbf916","47d61a2551a04df7bc7e09c2c01cb39c","68b8dd16a83d483587c1344c87155fa7","1244da88235e48dd826f8d7931272e68","cd667a12a6324e32956ed835df984c54","19ea94d484ba4bb0a8bd746594883f28","850e03530342477aae6bcb0164c5171c","056690c0a9474687900173dfdbb23594","6b351156f32d49a6be8e488aafc7e0a5","a9d93ca109d24b2d9ce482ef9871fb00","3e8418796cf64539b4456ff2f78f9609","48a42a3585064f688b17f60f3c7d91e3","df062863cfc444f493468b2c51246524","710effb279994c36a379815d224be005","62658c035c664b068d1ef3ba3b6ae07e","2e54ba7914c2470ab69998cb95a8381d","3ac38d88b4ba451bb5b1d09b222b271f","e938e27dae2e4350b8681c6678f152c1","2dd62006727a497589bff0a688494590","c61af47ee98c415a818850dae551fb7b","42a9a598f24c43f8a294767304d8bcdb","a6c995181b814f2c86f68a2624f37fd1","7817d964322040ba8b56f6543768eb15","9cd33ee73dca4f9487db5343b7a8c315","601e505208fc47dc834af8dff21f57cf","6c162d1c082a4b61b8d3b2298d11a82c","29b90f2eb2504f4ca5add525d0fa6b63","514688e156334916a816ad910a57a358","f6ea2672c2d242c8818fbe3223a53951","e9cf38d07db84a02a513db1266826d80","aff46372410c4ad5ba1eeedc48be1720","97e6b0a6b1fd4228a529aef6ae057d45","c0af238d0c0f4f5993fbd545b71d0989","642718567e864bf98632fd79bcb2e44b","4aae126dd0f34ea395fb81da61fab073","6771b94530754726911d7a14c36a1021","c5b4e72565384a28a198fef8df7f008e","591eef313e114336ad03f85e48659a2b","cd1aa0d7072b4c8fbe9a9bd6a99e6115","2d252e083fad4dcd8c1badee46c836f8","a8ddfa0f88b7445d8a0c2270f5cd4f68","78d14c2c5d05484a86c4ef06c10bf555","8170461969b6442e8a32087cafca68e0","199cc26e9d0c4f728dd2199874cbb1c2","0fc39407453b42ca8f12335d04d83424","606e91575d424e9793fa5b281671d258","edd487ddb75e4ab395d8bd2828437800","5b9c9126b8224c42af11af83f45c007d","a92fd572315940c6981a5294037f1cae","447c1ed8d66147269e1698ef49d93784","f431a6179edc458abb3db1fbe9f90a0c","eb6ed1a593c34f3b9162e2813f5a0389","95b4764e234342a38a4617c2851ebf60","2222cdae830e425796e51297a1265f96"]},"id":"dwAWl2DFhRk5","executionInfo":{"status":"ok","timestamp":1704567685518,"user_tz":-330,"elapsed":46791,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}},"outputId":"3ecad34c-7845-4e81-bfd3-3d77678e835d"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86efb7bb95a64da787c2184bd8a39aae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1c5671acb9c4046a3c056d1ce18e1c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"905fb04e74ad4dd28e7830471a8a1ba0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e8418796cf64539b4456ff2f78f9609"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6c995181b814f2c86f68a2624f37fd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0af238d0c0f4f5993fbd545b71d0989"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"199cc26e9d0c4f728dd2199874cbb1c2"}},"metadata":{}}]},{"cell_type":"code","source":["# Function to generate title from the given text\n","\n","def generate_title(text):\n","  prompt = f\"\"\"\n","    Give a suitable title explaining the following text.\n","\n","    {text}\n","\n","  \"\"\"\n","  inputs = tokenizer(prompt, return_tensors='pt')\n","  output = tokenizer.decode(\n","      model.generate(\n","          inputs[\"input_ids\"],\n","          max_new_tokens=100\n","          # min_length=50,\n","          # max_length=150,\n","          # num_beams=2\n","      )[0],\n","      skip_special_tokens=True\n","  )\n","  return output"],"metadata":{"id":"faCto9IhiABl","executionInfo":{"status":"ok","timestamp":1704567685519,"user_tz":-330,"elapsed":8,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Function to generate abstractive summary from the given text\n","\n","def generate_abstractive_summary(text):\n","  prompt = f\"\"\"\n","  Summarize the following text which corresponds to the research paper.\n","\n","  {text}\n","\n","  Summary:\n","    \"\"\"\n","  inputs = tokenizer(prompt, return_tensors='pt')\n","  output = tokenizer.decode(\n","      model.generate(\n","          inputs[\"input_ids\"],\n","          # max_new_tokens=100\n","          # min_length=50,\n","          # max_length=150,\n","          num_beams=2\n","      )[0],\n","      skip_special_tokens=True\n","  )\n","  return output"],"metadata":{"id":"HMXAs-Q4yjy4","executionInfo":{"status":"ok","timestamp":1704567685519,"user_tz":-330,"elapsed":7,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["for key, value in result_dict.items():\n","  para = value[\"paragraphs\"]\n","  ext_sum = generate_extractive_summary(para)\n","  title = generate_title(ext_sum)\n","  value[\"summary\"] = ext_sum\n","  value[\"title\"] = title"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EYFJaJFoiRo4","executionInfo":{"status":"ok","timestamp":1704567821110,"user_tz":-330,"elapsed":135597,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}},"outputId":"35c6c5b3-8ec3-4f4c-88a2-77f637dfe476"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["def generate_final_summary_title_dict(input_dict):\n","  for key, value in input_dict.items():\n","    para = value[\"paragraphs\"]\n","    ext_sum = generate_extractive_summary(para)\n","    if ext_sum == \"\":\n","      ext_sum = generate_abstractive_summary(para)\n","      title = generate_title(ext_sum)\n","    else:\n","      title = generate_title(ext_sum)\n","    value[\"summary\"] = ext_sum\n","    value[\"title\"] = title\n","  return input_dict"],"metadata":{"id":"LFX0qmSb2bmo","executionInfo":{"status":"ok","timestamp":1704567821111,"user_tz":-330,"elapsed":55,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Print the result\n","for key, value in result_dict.items():\n","    print(f\"{key}:\")\n","    print(f\"Headers: {value['headers']}\")\n","    print(f\"Paragraphs: {value['paragraphs']}\")\n","    print(f\"title: {value['title']}\")\n","    print(f\"summary: {value['summary']}\")\n","    print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ChJmx8l1iVxR","executionInfo":{"status":"ok","timestamp":1704567821111,"user_tz":-330,"elapsed":53,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}},"outputId":"5a777f8a-8052-4179-fcf3-289dbf3cb048"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Division_1:\n","Headers: \n","Paragraphs: In a combinatorial auction m heterogenous indivisible items are sold to n bidders. This paper considers settings in which the valuation functions of the bidders are known to be complement-free (a.k.a. subadditive). We provide several approximation algorithms for the social-welfare maximization problem in such settings. Firstly, we present a logarithmic upper bound for the case that the access to the valuation functions is via demand queries. For the weaker value queries model we provide a tight O( √ m) approximation. Unlike the other algorithms we present, this algorithm is also incentive compatible. Finally, we present two approximation algorithms for the more restricted class of XOS valuations: A simple deterministic algorithm that provides an approximation ratio of 2 and an optimal e e-1 approximation achieved via randomized rounding. We also present optimal lower bounds for both the demand oracles model and the value oracles model.\n","title: A combinatorial auction model for weaker value queries\n","summary: In a combinatorial auction m heterogenous indivisible items are sold to n bidders. For the weaker value queries model we provide a tight O( √ m) approximation.\n","\n","\n","Division_2:\n","Headers: \n","Paragraphs: 1. Introduction. This paper considers the allocation problem in combinatorial auctions. In a combinatorial auction, we have a set of heterogenous indivisible items that are sold to competing bidders. The bidders value bundles of items, rather than only valuing single items individually. Thus, bidders can express complex combinatorial preferences over items. Formally, a set M of items, |M |=m, is sold to n bidders. To denote the i'th bidder's value for each bundle of items S ⊆ M , we use a function v i , where v i (S) denotes the value of the bundle S for bidder i. The function v i is called the valuation of bidder i. Two common assumptions are that for each bidder i, v i is normalized (v i (∅) = 0), and monotone (for each S ⊆ T ⊆ M, v i (S) ≤ v i (T )). The goal is to partition the items between the bidders in a way that maximizes the social welfare -the sum of bidders' values for the bundles that are allocated to them. That is, we wish to find an allocation (S 1 , ..., S m ), S i ∩ S j = ∅ for i = j, that maximizes i v i (S i ). Two aspects make this problem hard to solve. Firstly, the \"input\" is of exponential size -a naive representation of a valuation will require 2 m values, one for each bundle -while we would like our algorithms to run in time that is polynomial in m and n (the natural parameters of the problem). Secondly, even for valuations that can be succinctly described, the optimization problem is computationally hard. Much work has addressed the problem of identifying special cases that can be efficiently solved or approximated, as well as understanding the underlying computational limitations -see chapters 10 -13 of Cramton et al.  There are two possible approaches to formalizing the computational model. These approaches differ in how the \"input\" is accessed. The first approach calls for fixing some bidding language in which the input valuations are encoded. This approach requires algorithms to run in time that is polynomial in the input length (under this encoding). This kind of approach makes sense in cases in which a sufficiently natural bidding language exists. The second approach treats the valuations as black boxes and assumes that each valuation is represented by oracles that can only answer a fixed type of queries. Three types of queries are commonly considered: (i) Value queries: The query specifies a subset S ⊆ M of items and receives the value v i (S) as the reply. This query is very natural from a computer science point of view, but, in general, is quite weak. (ii) Demand queries: The query specifies a vector p = (p 1 , ..., p m ) of \"item prices\", and the reply is the set that would be \"demanded\" by the queried bidder given these item prices, i.e., a subset S that maximizes the expression v i (S) -j∈S p j . This query is natural from an economic point of view as it corresponds to the revealed preferences of the bidders (i.e., what is directly observable from their behavior). Blumrosen and Nisan  (iii) General queries: In this model we allow the oracles to answer any kind of query (however, each query can only be addressed to a single valuation). This model captures the communication complexity (between the bidders) of the problem, and due to its strength is mostly interesting for proving lower bounds. Combinatorial auctions with general valuations are well understood from a computational perspective: the optimal allocation can be approximated to within a factor of O( √ m) in polynomial time, but not within a factor of m An important special case of combinatorial auctions is the one in which the valuations are known to be complement-free, i.e., all input valuations are known to be subadditive: v(S ∪ T ) ≤ v(S) + v(T ) for all S, T 1 . Lehmann et al.  The allocation problem becomes gradually harder as we move upwards within this hierarchy; a strongly polynomial time algorithm exists if the input valuations are given in the OXS language; a polynomial time algorithm, based on linear programming, exists for the class GS, as shown by Nisan and Segal  1.1 Upper Bounds. The main message relayed in this paper is that for the two higher levels of the hierarchy better upper bounds exist: Theorem 1.1 There exists a polynomial-time algorithm that finds an O( log m log log m ) approximation for valuations in the CF class, using demand queries. This algorithm is based on careful randomized rounding of the linear programming relaxation of the problem; a deterministic algorithm is obtained via derandomization. For the more restricted XOS class we obtain improved approximation ratios. Theorem 1.2 There exists a polynomial-time ( e e-1 )-approximation algorithm for valuations given in the XOS language. We also present a 2-approximation algorithm for this class. Although the approximation guarantee is worse than e e-1 , the 2-approximation algorithm has several advantages: it is combinatorial, fast, simple, and deterministic. Moreover, it serves as the main building block for constructions of truthful mechanisms for combinatorial auctions  1.2 Lower Bounds. We prove lower bounds for approximation for both CF and XOS. The class CF does not have a natural bidding language and so the lower bound is for the oracle model. The lower bound for the class XOS is actually two separate lower bounds: an NP-hardness result for the bidding language model, and a communication lower bound for the oracle model. No inapproximability result for any of these classes was previously known. Theorem 1.3 Exponential communication is required for approximating the optimal allocation among CF valuations to within a factor of 2 -, for any constant > 0. Theorem 1.4 (1) It is NP-hard to approximate the optimal allocation among valuations given in the XOS language to within any constant factor better than e/(e -1). (2) Exponential communication is required for approximating the optimal allocation among XOS valuations to within any constant factor better than e/(e -1). The last theorem shows that our algorithm for the class XOS is tight. 1.3 Handling Selfishness. In many settings in which the combinatorial auction problem arises, it is natural to assume that the bidders are selfish. That is, the bidders are interested only in maximizing their own utility, and might therefore misreport their preferences if it suits their interests. We are therefore interested in truthful algorithms that by introducing payments guarantee that if each bidder is to simply report his true value he will maximize his profit. Surprisingly, to date, very few computationally-feasible truthful mechanisms for this problem are known that do not apply only to very restricted single-parameter domains. We present an approximation algorithm that makes use of value queries only, and ensures truthfulness. Theorem 1.5 There exists a truthful polynomial-time algorithm that finds an O( √ m)-approximation for valuations in the class CF using value queries only. This approximation ratio may seem quite bad when contrasted with the fact that for the class of submodular valuations constant-approximation algorithms that use only value queries exist (e.g., by Lehmann et al.  1.4 Subsequent Work. Subsequently to this paper, Feige  We now discuss subsequent work related to submodular valuations. Khot, Lipton, Markakis, and Mehta  Vondrak  Another line of research which stemmed in this paper is obtaining truthful mechanisms for combinatorial auctions with complement-free valuations. Dobzinski  Dobzinski and Nisan  1.5 Open Questions. This paper and subsequent work determined the optimal bounds possible for the upper levels of the hierarchy, namely combinatorial auctions with XOS and complement-free valuations. • The main open question is closing the gap between the known upper and lower bounds for submodular valuations in the demand oracles model. In particular, no communication lower bound is known. • It would also be interesting to achieve these approximation ratios using combinatorial algorithms (most state-of-the-art algorithms are based on randomized rounding of the LP relaxation of the problem). • Another major open question which is still open is to determine how well truthful mechanisms can approximate the welfare in all levels of the hierarchy.\n","title: Allocation in combinatorial auctions\n","summary: This paper considers the allocation problem in combinatorial auctions. This kind of approach makes sense in cases in which a sufficiently natural bidding language exists. We prove lower bounds for approximation for both CF and XOS. In many settings in which the combinatorial auction problem arises, it is natural to assume that the bidders are selfish. We present an approximation algorithm that makes use of value queries only, and ensures truthfulness. The main open question is closing the gap between the known upper and lower bounds for submodular valuations in the demand oracles model.\n","\n","\n","Division_3:\n","Headers: Definition and Representation of XOS.\n","Paragraphs: This section discusses the definition and representation of XOS valuations. Recall, that as discussed in the introduction the class of XOS valuations strictly contains the class of submodular valuations  A valuation is called additive (a.k.a. linear) if for all S ⊆ M , v(S) = Σ j∈S v({j}). Thus, an additive valuation is defined by the values a 1 , ..., a m it assigns to items 1, ..., m respectively. We describe an additive valuations by the following clause: We can now define XOS valuations: where each of the clauses connected by the ⊕ sign represents an additive valuation. We note that the number of clauses t might be exponentially large. We call a clause of an additive valuation w, for which v(S) = max k {w k (S)}, a maximizing clause for S in v (if there are several such clauses we arbitrarily choose one). An XOS oracle is an oracle that given a bundle S returns a maximizing clause for S (for a specific valuation v). 2.1 Efficiently Simulating XOS and Demand Queries. We now show that if the input is given in the form of an XOS expression, XOS oracles and demand oracles can be simulated in time that is polynomial in the input size. We also prove that if all valuations are submodular then value queries can simulate XOS queries in polynomial time. Therefore, if all valuations are submodular, the algorithm presented in this section requires demand queries only (recall that a value query can be simulated by a polynomial number of demand queries  Proposition 2.1 Given an XOS valuation as an XOS expression, we can evaluate both XOS queries and demand queries in time polynomial in the input size. Proof. Given an XOS valuation and a vector of prices we wish to simulate a demand oracle. First, let us note that it is easy to simulate a demand oracle for an additive valuation in polynomial time, by simply choosing all profitable items. Since the input is given as an XOS formula and each clause is an additive valuation, it is enough to simulate a demand oracle for each clause and choose the most profitable option. The entire process requires time polynomial in the input size. If the input is not given as an XOS expression, then we do not know how to answer XOS queries given only a demand oracle. However, for the more restricted class of submodular valuations, even the weaker value oracle suffices to answer XOS queries, as the following proposition shows: Proposition 2.2 An XOS clause for a bundle S of a submodular valuation v can be calculated in polynomial time using value queries only. Proof. Given a bundle S we show how to construct the corresponding XOS clause. Fix some arbitrary order of the items in S. Without loss of generality, let S = {1, . . . , |S|}. Let t j be the marginal utility of the j'th item given the previous j -1 items: All that we have to prove is that v(S) = Σ j∈S t j , and that for every T ⊆ S, v(T ) ≥ Σ j∈T t i . For that we use an alternative definition of submodular valuations (see  The first property holds simply by construction. To see that v(T ) ≥ Σ j∈T t i , fix T , and let t T j be the marginal utility of item j in T , using the same order we used in S (that is, order the items in S, and delete items that are not in T , while keeping the relative order of the rest of the items). Recall that an alternative definition of submodular valuation says that the marginal utility does not decrease when items are deleted, hence v(T ) = Σ j∈T t T i ≥ Σ j∈T t i Finally, to show that this clause can be constructed using value queries only, observe that we only have to calculate the marginal utility of an item, which can be done by two value queries for each item. 3. Approximating the Welfare with Demand Oracles. Randomized rounding of an LPrelaxation of a problem is a standard technique, and our algorithms use it. However, when one attempts randomized rounding on packing problems such as combinatorial auctions the results are not good; A randomized choice will very likely yield non-feasible solutions, unless the probabilities chosen reduce the expected quality of solution by a large O( √ m) factor. Both algorithms we present in this section start with a randomized rounding procedure for obtaining a \"pre-allocation\". This allocation has a value that is close to the optimum, but unfortunately is not feasible. Feasibility issues are handled differently in the complement free and the XOS cases, and indeed a much better ratio is obtained for the XOS case. Before describing the randomized rounding procedure, let us recall the standard LP relaxation for combinatorial auctions: -For each item j: Σ i,S|j∈S x i,S ≤ 1 -for each bidder i: Σ S x i,S ≤ 1 -for each i, S: x i,S ≥ 0 Even though the linear program has exponentially many variables, it may still be solved in polynomial time. This is done by solving the dual linear program using the ellipsoid method. Using the ellipsoid method requires a \"separation\" oracle, and this may be directly implemented using the demand oracles of the bidders. This was first proven by Nisan and Segal  The pre-allocation is obtained via randomized rounding as follows: For each bidder i we independently choose a set S i by performing the following random experiment: each set S is chosen with probability x i,S , and the empty set is chosen with probability 1 -Σ S x i,S . Observe that the randomized rounding solution outputs an integral solution with an expected value of OP T * , the optimal fractional solution. However, the solution is not feasible, as an item might be allocated to more than one bidder. The two algorithms we present greatly differ in how they solve this infeasibility. A word about the oracles needed to implement our algorithms. The algorithm for complement-free valuations we present in this section requires access to a demand oracle (for each specific valuation v). Both algorithms for XOS valuations we present require in addition access to an XOS oracle. 3.1 Complement-Free Valuations. Indeed, the pre-allocation produces a non-feasible solution. However, these non-feasible solutions are only a logarithmic factor away from feasibility (in the sense that with high probability each item is allocated at most a logarithmic number of times). For general valuations this fact does not help, but as we will show it suffices for CF valuations (see also  The main observation at the heart of our algorithm is that one may partition this logarithmicallynon-feasible solution into a logarithmic-size family of feasible solutions. For the case of complement-free valuations, the quality of one of these solutions can be bounded from below. The original version of the algorithm claimed a ratio of O(log m). Feige  (i) Use randomized rounding to find a \"pre-allocation\" S 1 , ..., S n of pairs < i, S i > with the following properties, where k = O( log m log log m ): ). (ii) For each bidder i, partition S i into a disjoint union S i = S 1 i ∪ ... ∪ S k i such that for each 1 ≤ i 1 < i 2 ≤ n and 1 ≤ r ≤ k, it holds that S r i1 ∩ S r i2 = ∅. This is done as follows: for each i = 1, ..., n and each r = 1, ..., k, we let S r i = {j ∈ S i |j appears in exactly r -1 of the sets S 1 , ..., S i-1 }. (iii) Find the r that maximizes i v i (S r i ), and for each i allocate T i = S r i to bidder i. (iv) If there is a bidder i with v i (M ) ≥ Σ i v i (T i ) then allocate i all items (and allocate nothing to the rest of the bidders). We now prove the theorem. Towards this end, let us keep track of the \"quality\" of solution implied by the intermediate steps. (i) The randomized rounding procedure returns the optimal fractional solution OP T * = Σ i,S x i,S v i (S), which is an upper bound to the value of the integral optimal allocation, OP T . The detailed calculations needed to prove that this step indeed ends with a solution that satisfies all the required conditions are given later. At this point we will indicate the types of calculations used and what they yield. From the first inequality of the LP and using standard probability bounds one can show that for every item j, the probability that it appears in more than k chosen sets is exponentially small in k. The expected value of i v i (S i ) at this stage is only slightly less than Σ i,S x i,S v i (S) = OP T * . It follows that with very high probability none of the required constraints are violated, and thus we have The main point here is that indeed for every fixed r, the sets {S r i } i are pairwise disjoint and are thus a valid allocation. This follows directly from the construction, as every duplicate instances of every item j are allocated to sets S r i with sequentially increasing r. Note that we always keep r ≤ k since each item appears in at most k sets in {S i }. (iii) The crucial use of complement-freeness comes here: since for each fixed i, S i = r S r i , the fact that v i is complement free implies that r v i (S r i ) ≥ v i (S i ). By summing over all i we get that It is now clear that by choosing the r that maximizes i v i (S r i ) we get that i v i (S r i ) ≥ OP T * 3k . Thus, the allocation T 1 = S r 1 , ..., T n = S r n is an O( log(m) log log m ) approximation to the optimal allocation (and even to the optimal fractional allocation). 3.1.1 Details of Stage (i). For each j ∈ M , let E j denote the random variable that indicates whether j was allocated more than k times. Let B be the random variable that indicates whether v i (S i ) < 1  3 OP T * . We will prove that Pr[∨ j E j ∨ B] < 5 6 . We first prove that Pr[∨ j E j ] < 1 n . Fix an item j. Let Z i,j be the random variable that determines whether j ∈ S i . Obviously, Z i,j receives values in {0, 1}. Because of the randomized rounding method we used, we have that the variables {Z i,j } i are independent. We define Z j = Σ i Z i,j (i.e., Z j is the number of times item j appears in {S i }). By the linearity of expectation and the first condition of the LP formulation we have that E[Z j ] ≤ 1. We now use the following known proposition, (see, e.g., the book by Mitzenmacher and Upfal  and thus we have that Pr[item j appears in more than log m 3 log log m bundles in By applying the union bound we get that the probability that any one of the items appears in more than log m m . We will now prove that Pr[B] < 3 4 . W.l.o.g. max i v i (M ) = 1 (otherwise, we can divide all valuations by max i v i (M )). If OP T * ≤ 3, then giving M to the bidder that maximizes v i (M ), is a feasible allocation which provides a good approximation. Therefore, from now on we assume that OP T * > 3. Let A be the random variable that gets the value of Σ i v i (S i ) after step (i). We will see that A ≥ Σ i v i (S) 3 with high probability. We make use of the following corollary from Chebyshev's inequality: Lemma 3.2 Let X be the sum of independent random variables, each of which lies in [0, 1], and let We can now upper bound the probability that event B occurs. the last inequality is because OP T * > 3. Therefore, using the union bound: We have shown that with good probability it is possible to create a solution for which all the necessary conditions hold. 3.2 XOS Valuations. The algorithm presented in this section is based on exploiting the structure of the syntactically defined XOS class. Recall that the class of XOS valuations strictly contains submodular valuations. The algorithm starts by obtaining a pre-allocation as described in the beginning of the section, where each bidder gets at most one bundle. The next step is to \"replace\" the valuation of a bidder with the XOS clause that corresponds to the bundle he got in the pre-allocation. Now we find the optimal solution using the \"new\" valuations. Observe that a simple greedy algorithm finds the optimal allocation if all bidders have additive valuations. We are left with showing that the value of the generated allocation is not too far from the optimal fractional solution. Once again, the syntactic properties of XOS come to our aid: we analyze the algorithm by separately setting a lower bound on the contribution of each single item to the total social welfare. (i) Obtain a \"pre-allocation\" S 1 , ..., S n using the randomized rounding procedure. (ii) Let (x 1 : p i 1 ∨ ... ∨ x m : p i m ) be the maximizing clause for S i in v i . (iii) Allocate the j'th item to bidder i for which p i j ≥ p i j , for all i ∈ N . Note that Step (i) requires access to a demand oracle, and Step (ii) requires access to an XOS oracle. We do not know if an XOS oracle can be simulated using demand queries only, in the case of general XOS valuations. However, if a valuation is submodular, a demand oracle (and in fact, a value oracle) suffices, as was shown before. Thus, if all valuations are submodular only demand oracles are needed to implement the algorithm. Theorem 3.2 If all input valuations are XOS then the algorithm produces an allocation that is a ( Proof. Observe that the allocation produced by the algorithm is indeed a feasible one. Thus, all that is left to prove is that it achieves the desired approximation ratio. For every bidder i and bundle S, let (x 1 : p m ) be the maximizing clause for S in v i . It holds that: ) Let Q j be the random variable that equals max i∈N {p i j }, after the randomized rounding step. Let ALG be the random variable that receives the value of the total social welfare after assigning each item as in the algorithm. Due to the properties of XOS valuations, ALG ≥ Σ j Q j . This is because if (x 1 : p m ) is the maximizing clause of S in v i then, by XOS, for every T ⊆ S Σ j∈T p (i,S) j ≤ v i (T ). We will now show that the expectation of Q j is bounded from below by (1 ). Thus, by the linearity of expectation: Proof. Fix an item j. We will lower bound the expected value of E[Q j ] by considering a different way of assigning j. Let X j i = Σ S|j∈S x i,S and That is, X i is the probability that bidder i gets item j in the \"pre-allocation\", and V j i is the expected value of j to bidder i, conditioned on i receiving j in the \"pre-allocation\". Order the bidders in the decreasing order of their V j i 's. Without loss of generality, let us assume this order to be 1, ..., n. We assign j to the highest ranked (first) bidder who got item j in the \"pre-allocation\". Denote by T j the expected value of j in this allocation. Observe that is the expected value of item j when j is always assigned to the bidder with the highest (per-item) value for j in the \"pre allocation\" (as in the algorithm). Therefore, to prove the lemma we will bound E[T j ] from below. It is easy to see that Note that, due to the first condition of the LP, X j 1 + ... + X j n ≤ 1. Therefore, we have for every 1 ≤ k ≤ n that: 1 where the last two inequalities are derived using elementary calculus. Define V j n+1 = 0. Multiplying Equation 1 by (V j k -V j k+1 ) for every 1 ≤ k ≤ n, and summing over all k's shows that: We now present a 2-approximation algorithm for combinatorial auctions with XOS bidders. While the approximation guarantee is worse than the e e-1 guarantee of the previous algorithm, the current algorithm is combinatorial, fast, and simple. (i) Initialize S 1 = ... = S n = ∅, and p 1 , ..., p m = 0. (ii) For each bidder i = 1...n : (a) Let S i be the demand of bidder i at prices p 1 , ..., p m . (b) For all i < i take away from S i any items from S i : S i ← S i -S i . (c) Let (x 1 : q i 1 ∨, ..., ∨x m : q i m ) be the maximizing clause for S i in v i . (d) For all j ∈ S i , update p j = q i j . Notice that in Step (ii)a we require access to a demand oracle, and in Step (ii)c we require access to an XOS oracle.\n","title: XOS Valuation\n","summary: This section discusses the definition and representation of XOS valuations. We note that the number of clauses t might be exponentially large. Given an XOS valuation and a vector of prices we wish to simulate a demand oracle. Feasibility issues are handled differently in the complement free and the XOS cases, and indeed a much better ratio is obtained for the XOS case. This is done by solving the dual linear program using the ellipsoid method. Observe that the randomized rounding solution outputs an integral solution with an expected value of OP T * , the optimal fractional solution. However, the solution is not feasible, as an item might be allocated to more than one bidder. We will prove that Pr[∨ j E j ∨ B] < 5 6 . Fix an item j. Let Z i,j be the random variable that determines whether j ∈ S i . Because of the randomized rounding method we used, we have that the variables {Z i,j } i are independent. If OP T * ≤ 3, then giving M to the bidder that maximizes v i (M ), is a feasible allocation which provides a good approximation. Therefore, from now on we assume that OP T * > 3. Now we find the optimal solution using the \"new\" valuations. We are left with showing that the value of the generated allocation is not too far from the optimal fractional solution. However, if a valuation is submodular, a demand oracle (and in fact, a value oracle) suffices, as was shown before. It holds that: ) Let Q j be the random variable that equals max i∈N {p i j }, after the randomized rounding step. b) For all i < i take away from S i any items from S i : S i ← S i -S i . (\n","\n","\n","Division_4:\n","Headers: Theorem 3.3\n","Paragraphs: The algorithm provides a 2 approximation to the optimal allocation. Proof. For each T ⊆ M , we denote by p i (T ) the sum of the prices of the items in T at the i'th stage of the algorithm. Let ∆ i = p i (M ) -p i-1 (M ), i.e., the total difference in prices between stages (i -1) and i (with p 0 (M ) = 0). Let A 1 , ..., A n be the allocation generated by the algorithm. Let O 1 , ..., O n be the optimal allocation. We will prove the To do so, we prove three simple lemmas:\n","title: Allocation of items by price\n","summary: The algorithm provides a 2 approximation to the optimal allocation. For each T ⊆ M , we denote by p i (T ) the sum of the prices of the items in T at the i'th stage of the algorithm.\n","\n","\n","Division_5:\n","Headers: The social welfare of the allocation generated by the algorithm is at least the sum of items' prices at the end of the algorithm (after the n'th stage). That is, p\n","Paragraphs: Proof. Consider a specific bidder i. Let T be the bundle assigned to that bidder by the algorithm in stage i. Obviously A i ⊆ T . Because v i is an XOS valuation, we have that p i (A i ) ≤ v i (A i ). However, since the items in A i were not reassigned after the i'th stage, and so their prices were not altered, Lemma 3.5 The prices assigned to the items throughout the execution of the algorithm are non-decreasing. Proof. By contradiction. Let S be the set that maximizes the demand of the i'th bidder at the i'th stage of the algorithm. Let (x 1 : q 1 ∨ ... ∨ x m : q m ) be the XOS clause of S in v i . Now, assume there is an item j ∈ S for which q j < p i j . v i is an XOS valuation and so we have that Σ t∈(S-{j}) q t ≤ v i (S -{j}) and Σ r∈S q r = v i (S). Hence: and this is a contradiction to the definition of S. Lemma 3.6 The social welfare of the optimal allocation is at most twice the sum of items' prices at the end of the algorithm. That is, Proof. Recall that ∆ i represents the \"demand\" of player i at prices p i-1 . Hence, for each i, We have: since the prices do not decrease throughout the algorithm, the following inequality holds: by summing up on both sides of the equation we get: Putting the lemmas together we have that The following example shows that the algorithm cannot achieve an approximation ratio better than 2: consider a combinatorial auction with two goods, a and b, and two bidders. The first bidder's valuation is A welfare of 2 can be achieved by allocating a to the first bidder, and b to the second bidder. However, the first bidder might wish to get b at the first stage, and the optimal social welfare achieved is only 1. Hence, the approximation ratio achieved by the algorithm is not better than 2.  Proof. Nisan \n","title: XOS valuation of a bundle\n","summary: Consider a specific bidder i. Let T be the bundle assigned to that bidder by the algorithm in stage i. Obviously A i ⊆ T . v i is an XOS valuation and so we have that Σ t∈(S-{j}) q t ≤ v i (S -{j}) and Σ r∈S q r = v i (S).\n","\n","\n","Division_6:\n","Headers: Lower Bounds\n","Paragraphs: Let us now reduce this combinatorial auction to make the valuations complement free. Define new complement-free valuations as follows: v i (S) = v i (S) + 1, for S = ∅. These new valuations are indeed complement free, since the value of each non-empty bundle is at least 1, and no bundle has a value larger than 2. Consider an instance with valuations v 1 , . . . , v n . We can see that distinguishing between the following cases requires exponential communication: the optimal social welfare is n + 1, and the optimal social welfare is 2n (since distinguishing between these cases is equivalent to distinguishing between the corresponding cases in the auction presented in  4.2 Lower Bounds for XOS Valuations. We prove two lower bounds: one in the bidding language model (an NP-hardness result), and one communication lower bound. Theorem 4.2 It is NP-hard to approximate the optimal allocation among valuations given in the XOS language to within any factor better than e/(e -1), for n, m → ∞. Proof. We will show a polynomial-time reduction from MAX-k-COVER. MAX-k-Cover is defined as follows: Given m items, and a collection of subsets of these items, the objective is to maximize the number of items which can be covered by k subsets. Feige  Observe that every choice of k subsets in the MAX-k-COVER corresponds to an allocation in the combinatorial auction with the same value, by assigning all items in set i to bidder i (and avoid assigning one item to more then one bidder). In the other direction, every allocation corresponds to a choice of k sets in MAX-k-COVER with at least the social welfare value: choose k subsets, so that subset i contains the items in the clause maximizing bidder i's gain. Hence, we are guaranteed that the number of items covered is no less than the social welfare. The theorem follows. Next we prove an unconditional communication lower bound. The proof is based on reduction from the approximate-disjointness problem using a probabilistic construction. The reduction relies on a combinatorial structure that guarantees the required gap between the optimal solution and all other solutions. We first define this structure, and then prove its existence via the probabilistic method. Theorem 4.3 Every protocol for approximating combinatorial auctions with XOS bidders to a factor of for every > 0, requires exponential communication. This lower bound also applies for randomized settings. Proof. We will prove our lower bound by reducing from the approximate disjointness problem. In this problem, there are n players, each player i holds a string A i which specifies a subset of {1, ..., t}. The goal is to distinguish between the following two extreme cases: Alon et al.  We show a reduction from the approximate-disjointness problem on vectors of size t = e 2m n to the problem of finding an optimal solution in combinatorial auctions with XOS bidders. We then prove a communication lower bound for distinguishing between the case the optimal value is m and the case it is ]. We will create a set F = {P s } s=1,...,t , where each P s is a partition of M into n disjoint subsets {P 1 s i , ..., P n s i }. This set of partitions will have the following property: can only result in changing the allocation to a suboptimal one, hence decreasing the utility of the bidder. Thus bidding truthfully is the best action for each bidder The obvious drawback of using the VCG mechanism is that it requires us to find the optimal solution. In many settings finding the optimal solution is not computationally feasible, and this is true in particular in the settings considered in this paper. In general, obtaining an approximate solution using an approximation algorithm and using the VCG payment scheme (paying each bidder the sum of the utilities of the rest of the bidders) does not result in a truthful mechanism. In fact, Nisan and Ronen  An algorithm is maximal in range if it limits the range of possible allocations to a smaller set, and finds the optimal allocation within this restricted range. Incentive compatibility immediately follows using the same argumentation as before since we find the optimal allocation in the restricted range. The main challenge in the design of these algorithms is therefore to identify a subset of the range in which complete optimization is computationally feasible, and then showing that the optimal solution within the restricted set of solutions always provides the required approximation ratio.\n","title: A Communication Lower Bound for a ''Optimal Value'''\n","summary: Let us now reduce this combinatorial auction to make the valuations complement free. Hence, we are guaranteed that the number of items covered is no less than the social welfare. We will prove our lower bound by reducing from the approximate disjointness problem. We then prove a communication lower bound for distinguishing between the case the optimal value is m and the case it is ].\n","\n","\n","Division_7:\n","Headers: 5.2\n","Paragraphs: The Algorithm. We present a maximal in range algorithm for combinatorial auctions with complement-free bidders. This algorithm makes use of value queries only. The approximation ratio of this algorithm is O( √ m). In contrast, Dobzinski and Schapira  (i) Query each bidder i for v i (M ), and for v i ({j}), for each item j. (ii) Construct a bipartite graph by defining a vertex a j for each item j, and a vertex b i for each bidder i. Let the set of edges be E = ∪ i∈N,j∈M (a j , b i ). Define the cost of each edge (a j , b i ) to be v i ({j}). Compute the maximum weighted matching |P | in the graph. (iii) If the valuation of the bidder i that maximizes v i (M ) is higher than the value of |P |, allocate all items to i. Otherwise, for each edge (a j , b i ) ∈ P allocate the j'th item to the i'th bidder.\n","title: Maximized in range algorithm for combinatorial auctions\n","summary: We present a maximal in range algorithm for combinatorial auctions with complement-free bidders. Define the cost of each edge (a j , b i ) to be v i ({j}).\n","\n","\n","Division_8:\n","Headers: Theorem 5.1 If all the valuations are complement free, the algorithm provides an O( √ m)-approximation\n","Paragraphs: to the optimal allocation in polynomial time, and is incentive compatible. Proof. Observe that the algorithm's running time is polynomial in n and m, since maximal weighted matching in bipartite graphs can be solved in polynomial time (in m and n). The algorithm is clearly a maximal-in-range algorithm, and thus incentive compatibility is guaranteed by the use of the VCG payment scheme. Let us now prove that the algorithm provides the desired approximation ratio. Let OP T = {T 1 , ..., T k , Q 1 , ..., Q l } be the optimal allocation in the original auction, where for each 1 The first case we consider is when Σ √ m (otherwise, more than m items were allocated), for the bidder i that maximizes Thus, by assigning all items to bidder i we get the desired approximation ratio.\n","title: Maximization of the optimal allocation in polynomial time\n","summary: to the optimal allocation in polynomial time, and is incentive compatible. The algorithm is clearly a maximal-in-range algorithm, and thus incentive compatibility is guaranteed by the use of the VCG payment scheme.\n","\n","\n","Division_9:\n","Headers: Consider the case in which Σ\n","Paragraphs: |T i | (this is due to the CF property: By assigning c i to bidder i we get an allocation in which every bidder gets at most one item with a social welfare of Σ k i=1 v i ({c i }) m . The second allocation, therefore, guarantees at least that social welfare. We conclude that the approximation ratio the algorithm guarantees is at least O( √ m). 6. A Lower Bound for the Value Oracles Model. The proof of the lower bound takes a concrete complexity approach. That is, the input is given as a black box that can only answer a specific type of queries. We only measure the number of queries an algorithm must make in order to achieve a certain approximation ratio. In particular we ignore any computational work that needs to be done. We stress that the lower bound we achieve does not depend on any unproven computational assumption. Theorem 6.1 Approximating a combinatorial auction with XOS bidders to a factor of O(m 1 2 -), for any constant > 0, requires an exponential number of value queries. Proof. Fix a small constant δ > 0. We shall construct a combinatorial auction with m items and k = √ m bidders. For every S, let a S be the additive valuation that assigns a value of 1 to each item j ∈ S, and 0 to each item j / ∈ S. Let ā be the additive valuation that assigns every item j ∈ M a value of 1+δ {a S (T )}, ā(T )) Thus, each v i is a maximum over additive valuations, and thus is an XOS valuation. Choose, uniformly at random, a partition of the items into √ m disjoint bundles of items T 1 , . . . , T k such that for each i, |T i | = √ m. Define v 1 , . . . , v k as follows: v i (T ) = max{v i (T ), a T i (T )} Again, each v i is a maximum over additive valuations, and thus is an XOS valuation. We now prove that for every player i, it takes an exponential number of value queries to distinguish between the case that i's valuation is v i and the case that i's valuation is v i . Notice that the optimal welfare if the valuations are v 1 . . . , v k is Θ(m 1 2 +2δ ), while the optimal social-welfare if the valuations are v 1 . . . , v k is m. Hence, the fact that it requires an exponential number of value queries to distinguish between the valuation profiles v 1 . . . , v k and v 1 . . . , v k implies that an O(m 1 2 -2δ )-approximation algorithm requires an exponential number of value queries. Consider a specific player i. Fix a bundle S of at most m 1 2 +δ . It holds that v i (S) = max{|S|, (1 + δ)m 2δ }. v i might assign a value higher than v i to S but only if Observe that T i is selected uniformly at random. Thus, we can use the Chernoff bounds (Claim 4.2), and claim that Pr[|S ∩ T i | > (1 + δ)m 2δ ] is exponentially small. Now, consider a bundle S of size greater than m 1 2 +δ . v i will assign to S the value of (1 + δ) |S| m 1 2 -δ . v i might assign S a higher value, but only if Again, using the fact that T i is chosen uniformly at random we claim that that Pr[|S -δ ] is exponentially small. We conclude that for every bundle S, only with exponentially small probability does one gather sufficient information to distinguish between the case that i's valuation is v i and the case that it is v i . Hence, with constant probability it requires an exponential number of value queries to distinguish between v i and v i . This concludes the proof of the theorem.\n","title: A Lower Bound for the Value Oracles Model\n","summary: The second allocation, therefore, guarantees at least that social welfare. A Lower Bound for the Value Oracles Model. That is, the input is given as a black box that can only answer a specific type of queries. In particular we ignore any computational work that needs to be done. Thus, we can use the Chernoff bounds (Claim 4.2), and claim that Pr[|S ∩ T i | > (1 + δ)m 2δ ] is exponentially small.\n","\n","\n","Division_10:\n","Headers: 7.\n","Paragraphs: Acknowledgments. We thank Daniel Lehmann for comments on an earlier draft of this paper. This research is supported by a grant from the Israeli Science Foundation. The third author is supported by Supported by NSF grant 0331548.\n","title: A new study of the cellular dynamics of a saline aqueous solution\n","summary: We thank Daniel Lehmann for comments on an earlier draft of this paper. This research is supported by a grant from the Israeli Science Foundation.\n","\n","\n","Division_11:\n","Headers: \n","Paragraphs: Definition 4.1 A set of partitions F = {P s } s=1,...,t is said to have the (n, )-covering property if for every choice of indices 1 ≤ s 1 , s 2 , ...s n ≤ t, such that no two are equal, it holds that Lemma 4.1 For every > 0, there exists a set F of partitions with the (n, )-covering property of size Proof. We use probabilistic construction to obtain such a set: each partition P s will be chosen independently at random (each element will be placed in exactly one of the P i s with equal probability). We will require the following version of the Chernoff bounds: Lemma 4.2 Let X 1 , ..., X m be independent random variables that take values in {0, 1}, such that for all i, Pr[X i = 1] = p for some p. Then, the following holds, for 0 ≤ ≤ 1: Fix indices: 1 ≤ s 1 , s 2 , ..., s n ≤ t, such that no two are equal. For every j ∈ M let Y j be the random variable that receives a value of 1 if j ∈ ∪ n i=1 P i si and 0 otherwise. Observe that Using the last claim, we have that for any 0 < < 1: Since there are at most t n choices of such indices we have that as long as t n < e such a set of partitions exists. We are now left with describing the reduction. Assume an instance of the approximate-disjointness problem on vectors of size t = e , in which player i receives the string A i ⊆ {1, ..., t}. We reduce it into a combinatorial auction with n bidders, each with XOS valuation, in the following manner: Let M = {1, ..., m}. Player i will construct the collection B i = {P i s |s ∈ A i }. Bidder i's valuation will consist of |B i | clauses: ⊗ T ∈B i (∨ t∈T t = 1). In words, each clause corresponds to a set the player is interested in, and this clause gives a value of 1 to an item if it belongs to the wanted set, and 0 otherwise. Observe that if there exists s ∈ ∩A i , then there is an allocation in which all items are allocated, and the value of the bundle each player gets is simply the number of items he gets. Thus, the value of this allocation is m. On the other hand, if for every i = j, A i ∩A j = ∅ then the value of the optimal solution is at most The second observation is since the sets have the (n, )-covering property, so the players get together a value of at most ((1 )m from the allocated items. Since the communication complexity of the approximate-disjointness problem is Ω( t n 4 ), in our case it is Ω(e ). In particular, as long as m 1-> n, and for any constant 0 < < 1, the communication complexity is exponential. This concludes the proof of the theorem. 5. Truthful Approximations using Value Queries. 5.1 VCG and Maximal in Range Algorithms. Arguably the main positive result of mechanism design is the VCG payment scheme. Let us describe this payment scheme when applied to combinatorial auctions. First, find the optimal solution (O 1 , ..., O n ), and allocate accordingly. Then, pay each bidder the sum of the utilities of the rest of the bidders. That is, bidder i receives a payment of Σ k =i v k (O k ). Let us examine the total utility of bidder i: v i (O i ) + Σ k =i v k (O k ) (the value he gains from the bundle he got plus his payment). Hence, the total utility of each bidder is equal to the value of the allocation. Observe that the allocation that maximizes the utility of the bidders is the optimal one. Bidding untruthfully\n","title: Reduction of the approximate-disjointness problem\n","summary: For every j ∈ M let Y j be the random variable that receives a value of 1 if j ∈ ∪ n i=1 P i si and 0 otherwise. We are now left with describing the reduction. Since the communication complexity of the approximate-disjointness problem is Ω( t n 4 ), in our case it is Ω(e ). Then, pay each bidder the sum of the utilities of the rest of the bidders.\n","\n","\n"]}]},{"cell_type":"code","source":["# Extract data from slides for evaluation\n","\n","presentation_slide_file_path = \"/content/Slides_cf.pdf.tei.xml\"\n","result_dict_slides = extract_section_wise_text_from_file(presentation_slide_file_path)\n","\n","# combining the content for each division\n","for key, value in result_dict_slides.items():\n","    value[\"headers\"] = \" \".join(value[\"headers\"])\n","    value[\"paragraphs\"] = \" \".join(value[\"paragraphs\"])\n","\n","\n","# Remove duplicate entries\n","\n","# Dictionary to track values and their corresponding keys\n","value_counts = []\n","\n","# List to store keys to remove\n","keys_to_remove = []\n","\n","# Iterate through the original dictionary\n","for key, value in result_dict_slides.items():\n","    # If the value is already in the value_counts dictionary, add the key to the keys_to_remove list\n","    if value[\"paragraphs\"] in value_counts or value[\"paragraphs\"] == \"\":\n","        keys_to_remove.append(key)\n","    else:\n","        # Otherwise, add the value to the value_counts dictionary\n","        value_counts.append(value[\"paragraphs\"])\n","\n","# Remove the keys outside the loop\n","print(keys_to_remove)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7YtLl_2wlmS5","executionInfo":{"status":"ok","timestamp":1704567821112,"user_tz":-330,"elapsed":52,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}},"outputId":"221872d1-aeec-422b-c6d4-5ab62e273775"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["['Division_29', 'Division_30']\n"]}]},{"cell_type":"code","source":["for key in keys_to_remove:\n","    result_dict_slides.pop(key)"],"metadata":{"id":"Y8e7k0JBl3vd","executionInfo":{"status":"ok","timestamp":1704567821112,"user_tz":-330,"elapsed":32,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# combining all text 0f slides into a single object for evaluation\n","\n","def combine_all_text_of_slides_dict(input_dict):\n","  final_text = \"\"\n","  for key, value in input_dict.items():\n","    final_text += value[\"headers\"] + \"\\n\"\n","    final_text += value[\"paragraphs\"] + \"\\n\"\n","\n","  return final_text"],"metadata":{"id":"WKbazslKiquH","executionInfo":{"status":"ok","timestamp":1704567821112,"user_tz":-330,"elapsed":31,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# combining all summarized text into a single object for evaluation\n","\n","def combine_all_text_of_paper_summary_dict(input_dict):\n","  final_text = \"\"\n","  for key, value in input_dict.items():\n","    final_text += value[\"title\"] + \"\\n\"\n","    final_text += value[\"summary\"] + \"\\n\"\n","\n","  return final_text"],"metadata":{"id":"s3CrIIAfl9YA","executionInfo":{"status":"ok","timestamp":1704567821112,"user_tz":-330,"elapsed":31,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["slide_full_summary = combine_all_text_of_slides_dict(result_dict_slides)\n","slide_full_summary = slide_full_summary.replace(\"\", \"\")\n","\n","full_paper_summary = combine_all_text_of_paper_summary_dict(result_dict)\n"],"metadata":{"id":"wTB6tUcTmCW2","executionInfo":{"status":"ok","timestamp":1704567821113,"user_tz":-330,"elapsed":32,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Evaluation of the results\n","\n","!pip install evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"prL0mNOomVe3","executionInfo":{"status":"ok","timestamp":1704567830978,"user_tz":-330,"elapsed":9897,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}},"outputId":"d6eac9fc-ac3c-4fe2-96ed-4921e83cfb5c"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n","  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n","Collecting dill (from evaluate)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n","Collecting multiprocess (from evaluate)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n","Collecting responses<0.19 (from evaluate)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (10.0.1)\n","Collecting pyarrow-hotfix (from datasets>=2.0.0->evaluate)\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.3.post1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","Installing collected packages: pyarrow-hotfix, dill, responses, multiprocess, datasets, evaluate\n","Successfully installed datasets-2.16.1 dill-0.3.7 evaluate-0.4.1 multiprocess-0.70.15 pyarrow-hotfix-0.6 responses-0.18.0\n"]}]},{"cell_type":"code","source":["!pip install rouge_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5YPir7OMmfIb","executionInfo":{"status":"ok","timestamp":1704567842202,"user_tz":-330,"elapsed":11231,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}},"outputId":"ac01e1d1-84e2-4fe0-938b-74ff6a55d03c"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.23.5)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.1)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=c010b3f9dcc7bf255e6e11e94689e867348ef8edeb98c7dda9e2e35c4dff8260\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n"]}]},{"cell_type":"code","source":["# Evaluation of the summarized text with the reference slide text\n","\n","from evaluate import load\n","# Load the ROUGE metric\n","import evaluate\n","rouge = evaluate.load('rouge')\n","\n","listed_full_paper_summary = [full_paper_summary]\n","listed_slide_full_summary = [slide_full_summary]\n","\n","rouge_scores = rouge.compute(\n","    predictions=listed_full_paper_summary,\n","    references=listed_slide_full_summary,\n","    use_aggregator=True,\n","    use_stemmer=True,\n",")\n","\n","print(rouge_scores)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["1faf2e8baa724b269ac28fa108481c5d","c2783f1a0696425aba4d4ca414d22609","47d1b9e5332f486cbc8b911b7b02d822","3a57f17967cf480cbd68d67c0b0e8ecf","b4374a7c4098435e9ad6d93f6ce88d6f","97c93715285d44f09dcfbadef58e5cad","2df0faf25a1c4c58a664d846b6f7985e","2126adf9263f413ebd331ebd622249a6","6d9f700fd7df48a39ffdc7a22a8ffc59","11630bc12b134903a472e06dfd73866d","7585d17aa6c9485aa7ee33e038ff7967"]},"id":"yGMWogVgmj2R","executionInfo":{"status":"ok","timestamp":1704567848323,"user_tz":-330,"elapsed":6144,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}},"outputId":"f620f8e1-f96f-42bd-fdc5-08636f3380a4"},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1faf2e8baa724b269ac28fa108481c5d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["{'rouge1': 0.4424379232505643, 'rouge2': 0.17360438851242338, 'rougeL': 0.16510802966784907, 'rougeLsum': 0.40180586907449206}\n"]}]},{"cell_type":"code","source":["# creating presentation from the section wise summarized research data\n","\n","!pip install python-pptx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cbFfVzHdmxhq","executionInfo":{"status":"ok","timestamp":1704567858306,"user_tz":-330,"elapsed":9990,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}},"outputId":"be73d1c6-b8fc-4624-875a-d54bd6787a2a"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-pptx\n","  Downloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/471.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/471.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (4.9.4)\n","Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx) (9.4.0)\n","Collecting XlsxWriter>=0.5.7 (from python-pptx)\n","  Downloading XlsxWriter-3.1.9-py3-none-any.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: XlsxWriter, python-pptx\n","Successfully installed XlsxWriter-3.1.9 python-pptx-0.6.23\n"]}]},{"cell_type":"code","source":["\n","# import Presentation class\n","# from pptx library\n","from pptx import Presentation\n","from pptx.util import Inches, Pt"],"metadata":{"id":"xJ1X7h_sm94Z","executionInfo":{"status":"ok","timestamp":1704567859093,"user_tz":-330,"elapsed":804,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# Function to create first title slide\n","\n","def create_title_slide(pres, title):\n","  first_slide_layout = pres.slide_layouts[0]\n","  slide = pres.slides.add_slide(first_slide_layout)\n","\n","  slide.shapes.title.text = title\n","  return pres\n"],"metadata":{"id":"cvZ3vtP7GzPN","executionInfo":{"status":"ok","timestamp":1704567940506,"user_tz":-330,"elapsed":504,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["# Function to convert text into the slide\n","\n","\n","def create_slide_from_text(pres, title, summary):\n","  listed_summary = summary.split(\".\")\n","  bullet_slide_layout = pres.slide_layouts[1]\n","  slide = pres.slides.add_slide(bullet_slide_layout)\n","  shapes = slide.shapes\n","\n","  title_shape = shapes.title\n","  body_shape = shapes.placeholders[1]\n","\n","  title_shape.text = title\n","  tf = body_shape.text_frame\n","  # tf.text = listed_summary[0]\n","\n","  for i, v in enumerate(listed_summary):\n","    if i < 6:\n","      p = tf.add_paragraph()\n","      p.text = v\n","      p.font.size = Pt(22)\n","    else:\n","      break\n","\n","  return pres"],"metadata":{"id":"nVLqu3nxnBzn","executionInfo":{"status":"ok","timestamp":1704567859093,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["# create presentation from the title and summaries\n","\n","prs_1 = Presentation()\n","prs_1 = create_title_slide(prs_1, paper_title)\n","for k, v in result_dict.items():\n","  prs_1 = create_slide_from_text(prs_1, v[\"title\"], v[\"summary\"])\n","\n","prs_1.save(\"test1.pptx\")"],"metadata":{"id":"Kj1XDuj6nNyG","executionInfo":{"status":"ok","timestamp":1704567956055,"user_tz":-330,"elapsed":789,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["# You can check the test1.pptx file saved in the current directory.\n","\n","# Now applying the same functionalities to generate the presentation for another file."],"metadata":{"id":"fPONsPaEnJ-K","executionInfo":{"status":"ok","timestamp":1704567981423,"user_tz":-330,"elapsed":647,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# Final function combining all the functionalities which will take file path as input and will save presentation in the current folder\n","\n","def p2s_converter(file_path):\n","  r_dict = extract_section_wise_text_from_file(file_path)\n","  title = extract_title_from_file(file_path)\n","  r_dict = combine_content_for_each_division(r_dict)\n","  r_dict = remove_duplicate_entries(r_dict)\n","  f_dict = generate_final_summary_title_dict(r_dict)\n","  n_pres = Presentation()\n","  n_pres = create_title_slide(n_pres, title)\n","  for k, v in f_dict.items():\n","    n_pres = create_slide_from_text(n_pres, v[\"title\"], v[\"summary\"])\n","\n","  n_pres.save(\"reference.pptx\")\n","  return print(\"Presentation created for the given file path!\")\n"],"metadata":{"id":"0vANgAYR3PhB","executionInfo":{"status":"ok","timestamp":1704567985696,"user_tz":-330,"elapsed":587,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["# User can call this function after loading the required libraries directly with the xml file path\n","\n","p2s_converter(\"/content/2021.sdp-1.11.pdf.tei.xml\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9mJTD5j6c91","executionInfo":{"status":"ok","timestamp":1704568034212,"user_tz":-330,"elapsed":42610,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}},"outputId":"bb06287f-f71a-4550-cb19-224102a072c0"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Title Text: Extractive Research Slide Generation Using Windowed Labeling Ranking\n","['Division_13']\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Presentation created for the given file path!\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NJjRHmPAnXjQ","executionInfo":{"status":"ok","timestamp":1704568137283,"user_tz":-330,"elapsed":476,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["# Scope\n","\n","# Not able to use pdf figure 2.0 as the documentation available is not much clear.\n","\n","# Tried image extraction using different methods but was not able to find out correct algorithm to add the images in the slide\n","# as image with caption was not able to extract from the file hence excluding image addition part for now.\n","\n","# Following is the procedure that can be used to add images to the slide\n","#  - Extract image along with the image caption\n","#  - Check the caption from the extracted headers\n","#  - Associate that image to the header which is having max similarity\n","\n","# We can even improve the summarries by fine tuning the model for the given dataset.\n","# Can find even better LLM model to create bullet points from the summary got from Extractive Summarization."],"metadata":{"id":"mO1ncmzLb5oW"}},{"cell_type":"code","source":[],"metadata":{"id":"X2iF2KWOqv1j","executionInfo":{"status":"ok","timestamp":1704568138943,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"D8EZVU9jrdMu","executionInfo":{"status":"ok","timestamp":1704568141437,"user_tz":-330,"elapsed":3,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iKhLu3Twrolr","executionInfo":{"status":"ok","timestamp":1704568144366,"user_tz":-330,"elapsed":2,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Q4DMJfAjr4WQ","executionInfo":{"status":"ok","timestamp":1704568146839,"user_tz":-330,"elapsed":500,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_5GiQX4osHa1","executionInfo":{"status":"ok","timestamp":1704568148987,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"li4zWC3JuB9z","executionInfo":{"status":"ok","timestamp":1704568152689,"user_tz":-330,"elapsed":481,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-dvNyXhMxGvN","executionInfo":{"status":"ok","timestamp":1704568152690,"user_tz":-330,"elapsed":5,"user":{"displayName":"Rohit Karake","userId":"11862050568878033252"}}},"execution_count":46,"outputs":[]}]}